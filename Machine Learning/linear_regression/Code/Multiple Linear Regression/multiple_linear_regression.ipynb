{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "077feb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa174f",
   "metadata": {},
   "source": [
    "#                                           Multiple Linear Regression from Scratch\n",
    "```js\n",
    "        Work :\n",
    "        ------\n",
    "                We have N Input columns and 1 Output column. After training, the model tries to PREDICT the outcome for new inputs which may or may not be same as the Actual Output, mostly it will be around the actual output.\n",
    "\n",
    "        Also compare our model built from Scratch with Sklearn Linear Regression model to see if we are correct or not.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1d5620c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Our MLR Model\n",
      "Intercept = 151.8833100525417.\n",
      "\n",
      "Coefficients (for 10 input columns) = \n",
      "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
      "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238].\n",
      "\n",
      "For [[ 0.06713621 -0.04464164  0.00349435  0.03564379  0.0493413   0.03125356\n",
      "   0.07072993 -0.03949338 -0.00061174  0.01963284]], the predicted value = 154.12138809538385.\n",
      "\n",
      "                               Sklearn Linear Regression Model\n",
      "Intercept = 151.88331005254167.\n",
      "\n",
      "Coefficients (for 10 input columns) = \n",
      "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
      "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238].\n",
      "\n",
      "For [[ 0.06713621 -0.04464164  0.00349435  0.03564379  0.0493413   0.03125356\n",
      "   0.07072993 -0.03949338 -0.00061174  0.01963284]], the predicted value = 154.1213880953837.\n"
     ]
    }
   ],
   "source": [
    "class My_MLR: # The handwritten calculations are shown in \"Multiple Linear Regression Calculation\" pdf.\n",
    "    def __init__(self): # But only the FINAL Equations are in the LAST SECOND PAGE.\n",
    "        self.coefficients = None # B1, B2, ...., Bn  (B = Beta = Slope)\n",
    "        self.intercept = None    # B0\n",
    "    \n",
    "    def fit(self, x_train: np.ndarray, y_train: np.ndarray) -> None:\n",
    "        x_train = np.insert(arr=x_train, obj=0, values=1, axis=1)\n",
    "\n",
    "        betas = np.linalg.inv(np.dot(x_train.T, x_train)) .dot(x_train.T) .dot(y_train)\n",
    "\n",
    "        self.intercept, self.coefficients = betas[0, 0], betas[1:, 0]\n",
    "        print(f\"Intercept = {self.intercept}.\\n\")\n",
    "        print(f\"Coefficients (for {x_train.shape[1] - 1} input columns) = \\n{self.coefficients}.\\n\")\n",
    "    \n",
    "    def predict(self, x_test: np.ndarray):\n",
    "        return np.dot(x_test, self.coefficients) + self.intercept\n",
    "    \n",
    "\n",
    "def main():\n",
    "    X, Y = load_diabetes(return_X_y=True) # x.shape = (442, 10), y.shape = (442,).\n",
    "    Y = np.reshape(a=Y, newshape=(Y.shape[0], 1)) # y.shape = (442, 1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "    \n",
    "    #                                       Using our Custom MLR Model Object.\n",
    "    print(\"                                 Our MLR Model\")\n",
    "    mlr_obj1 = My_MLR()\n",
    "    mlr_obj1.fit(x_train=x_train, y_train=y_train)\n",
    "    print(f\"For {x_test[0:1][0:1]}, the predicted value = {mlr_obj1.predict(x_test[0:1][0:1]) [0]}.\")\n",
    "\n",
    "    #                                       Using Sklearn LR Model.\n",
    "    print(\"\\n                               Sklearn Linear Regression Model\")\n",
    "    mlr_obj2 =  LinearRegression()\n",
    "    mlr_obj2.fit(X=x_train, y=y_train)\n",
    "    print(f\"Intercept = {mlr_obj2.intercept_[0]}.\\n\")\n",
    "    print(f\"Coefficients (for {X.shape[1]} input columns) = \\n{mlr_obj2.coef_[0]}.\\n\")\n",
    "\n",
    "    print(f\"For {x_test[0:1][0:1]}, the predicted value = {mlr_obj2.predict(x_test[0:1][0:1]) [0][0]}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "explanation = \"\"\"\n",
    "    mlr_obj_.predict(x_test[0:1][0:1]   =   [[154.1213881]], because ML Model only accepts 2D Data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844793c",
   "metadata": {},
   "source": [
    "```js\n",
    "    If you want to see how a regression line i.e. \"HYPER PLANE\" looks like in ND Dimension, for convenience e.g. how a \"Plane\"/Regression_Line looks  like in 3 Dimensions i.e. 3 Columns, see the Last Graph of => https://colab.research.google.com/github/campusx-official/100-days-of-machine-learning/blob/main/day50-multiple-linear-regression/multiple_linear_regression.ipynb#scrollTo=NpAvnU-t3yV0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdefd6cd",
   "metadata": {},
   "source": [
    "#                                   Evaluate the Performace of Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8df8ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error = 45.21303419046903\n",
      "mean_squared_error = 3094.4566715660626\n",
      "Root mean_squared_error = 55.627840795469155\n",
      "\n",
      "R2 Score = 0.4399338661568968\n",
      "adjusted_r2_score = 0.3681305156641912\n"
     ]
    }
   ],
   "source": [
    "#                                                 1) Train the Model\n",
    "\n",
    "X, Y = load_diabetes(return_X_y=True) # x.shape = (442, 10), y.shape = (442,).\n",
    "Y = np.reshape(a=Y, newshape=(Y.shape[0], 1)) # y.shape = (442, 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "mlr_obj =  LinearRegression()\n",
    "mlr_obj.fit(X=x_train, y=y_train)\n",
    "y_predict = mlr_obj.predict(x_test)\n",
    "\n",
    "#                                    2) Calculate the Performance Measuring Matrices.\n",
    "\n",
    "print(\"mean_absolute_error =\", mean_absolute_error(y_true=y_test, y_pred=y_predict)) # returns 'loss'. The less, the good.\n",
    "print(\"mean_squared_error =\",  mean_squared_error(y_true=y_test, y_pred=y_predict)) # returns 'loss'. The less, the good.\n",
    "print(\"Root mean_squared_error =\", np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_predict)))\n",
    "\n",
    "r2_scoree = r2_score(y_true=y_test, y_pred=y_predict)\n",
    "print(\"\\nR2 Score =\", r2_scoree)\n",
    "\n",
    "n = x_test.shape[0] # x_test, y_test, y_predict, they all have same shape. Any one works.\n",
    "k = X.shape[1] # number of input columns.\n",
    "adjusted_r2_score = 1 - ((1-r2_scoree) * (n-1)/(n-1-k))\n",
    "print(\"adjusted_r2_score =\", adjusted_r2_score) # always check both r2_score and adjusted_r2_score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
