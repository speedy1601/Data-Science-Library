Paper Name,Abstract,Year,Conferance Name,Link,Fitzpatrick Dataset,Other Datasets,Model Used,Model Accuracy,Limitations
Achieving Fairness in Dermatological Disease Diagnosis through Automatic Weight Adjusting Federated Learning and Personalization,"Dermatological diseases affect nearly a third of the global population, and early diagnosis is crucial. Deep Learning based smartphone apps timely identify issues that have emerged around
users skins. Collecting sufficient data by deep learning with protecting patient privacy, federated learning is often used but it overlook imbalances in dermatology datasets due to the lack of Dark Skin types.
Hence, this paper proposes a fairness-aware federated learning framework to address these disparities in dermatological disease diagnosis.The framework is divided into two stages: In-FL and Post-FL.",2022,None,https://arxiv.org/abs/2208.11187,Fitzpatrick 17k,,Fairness-Aware Federated Learning Framework,https://docs.google.com/spreadsheets/d/1DFymohSaEJcIV254XQvtwcvzKoeqk-xvv4CpLd4sV3I/edit?usp=sharing,None
Does the Fairness of Your Pre-Training Hold Up? Examining the Influence of Pre-Training Techniques on Skin Tone Bias in Skin Lesion Classification,"Deep Neural Networks (DNNs) can be biased due to unbalanced training datasets during Pre-Training, leading to the DNNs making biased decisions, even when trained on unbiased datasets. This study compares the performance of pre-trained models to supervised learning backbones on two skin lesion datasets with different skintone distributions revealing Pre-Training improves performance but has a trade-off with fairness.",2024,"Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops, 2024.",https://openaccess.thecvf.com/content/WACV2024W/Pretrain/html/Seth_Does_the_Fairness_of_Your_Pre-Training_Hold_Up_Examining_the_WACVW_2024_paper.html,"Fitzpatrick 17k and
ISIC 2019.",,"1) ViT-32b is used with MAE and SimMIM (MIM methods).
2) ResNet-34 is used with BYOL, MOCO, SimCLR, and VICRegL (SSL methods).
3) ViT-16b is used in a supervised learning setup.",https://docs.google.com/spreadsheets/d/17wsnQDwxyj-swMWBMeIaEpdSc7EUinB2I7FcNQFopaM/edit?usp=sharing,"Models that are pre-trained
on large datasets may perform better, but they may also be more likely to make errors for patients with darker skin
tones due to the lack of diversity in pre-training datasets."
FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis,"FairTune, a framework that optimizes parameter-efficient fine-tuning (PEFT) techniques to balance the trade-off between task performance and fairness. By focusing on validation fairness, FairTune improves fairness across various medical imaging datasets. Our empirical results demonstrate the effectiveness of FairTune in reducing demographic bias, making it a valuable tool for ethical AI in medical applications.",2024,International Conference on Learning Representations 2024,https://arxiv.org/abs/2310.05055,"The selection of datasets was based on five integral factors: a) the presence of sensitive attributes, b) the presence of different potential sources of bias, c) the representation of different anatomical regions (domains), d) varying size, and e) public availability for reproducibility. we created random
 splits of the entire dataset into training, validation and test with proportions of 80%, 10%, 10%.
 Next, we binarized the prediction labels and the sensitive attributes. Sensitive Attribute Skin Type: In relation to the sensitive attribute skin type we delineate two groups. The first group encompasses samples with skin types ranging from 0 to 2, while the second group comprises samples with skin types exceeding 2.Sensitive Attribute Age: For the datasets HAM10000, Papila, OL3I, Oasis, Harvard-GF3300, and CheXpert, we establish two distinct categories to categorize the sensitive attribute age: one encompassing ages ranging from 0 to 60, and the other comprising individuals with ages exceeding 60. Sensitive Attribute Race: We created two categories with ‘Black’ patients belonging to the first and ‘Asian’ or ‘White’ patients belonging to the second. Overlapping Sensitive Attributes (Age+Gender): We created a new category of sensitive at tributes by combining Age and Gender. For Fitzpatrick17k: The first group includes samples labelled as malignant, while the second group contains samples with all other remaining labels."," HAM10000: Weconvertthe original labels into two categories: benign and malignant. The former
 contained samples with original labels ‘bcc’, ‘bkl’, ‘dermatofibroma’, ‘nv’, ‘vasc’ while the latter
 category contained samples labelled as ‘akiec’, and ‘mel’.
 Papila: We used samples belonging to ‘healthy’ and ‘glaucoma’ categories while samples from the
 ‘suspect’ class was excluded.
 OL3I: The original dataset already contains binary categories.
 Oasis-1: The ‘CDR’ labels 0, 0.5 and 1 into one category and label 2.0 into the other category.
 Harvard-GF3300: The original labels are already categorized into two categories: Glaucoma and
 Non-Glaucoma.
 CheXpert: Originally, each sample in the dataset can correspond to one or more of the 14 labels.
 We used the ‘No-Finding’ label for training, validation and testing (as done in Zong et al. (2023))
 since it is the only binary classification label."," Parameter-Efficient Fine-Tuning methods, A Framework named Fairtune",https://docs.google.com/spreadsheets/d/1A2LVEZOD_nSP6viBGn9IC_TkB1YSTcR6ibc0rwG8u8k/edit?usp=sharing,"Improving fairness in the model’s performance requires a lot of computational effort. This is because we need to test many different configurations, and each test means retraining the model. For example, their full FairTune process takes 48 GPU hours on the Fitzpatrick17k dataset, while unoptimized training only takes about 1 hour, and their baseline fine-tuning takes 14 GPU hours."
Unsupervised SoftOtsuNet Augmentation for Clinical Dermatology Image Classifiers,"This paper provides a comprehensive review of various machine learning techniques used for cancer detection and diagnosis. It explores the application of algorithms such as support vector machines, neural networks, and decision trees in identifying and classifying cancerous cells. The review highlights the strengths and limitations of each technique, emphasizing their accuracy, computational efficiency, and potential for clinical implementation. The paper also discusses the integration of machine learning models with medical imaging and genomic data to enhance diagnostic precision. Future directions for research and the challenges in translating these techniques into clinical practice are also addressed.",2024,PubMed Central,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10785922/,"Fitzpatrick17 consists of 16,577 images across 114 diagnoses, representing all six Fitzpatrick skin types. We cross validate with five random stratified splits of 80% training and 20% validation (separate from the split on which we tuned our algorithm).We train using PyTorch’s autocast function so that the computations are performed with 16-bit floating point values. The classifier networks are initialized with pretrained weights from an EfficientNet trained on ImageNet data20 and Noisy Student self-training.","DDI: This is a small dataset of 656 clinical dermatology images representing 78 separate diagnoses categorized into either “malignant” or “not malignant”. This is too small a dataset, with too many unique classes, to effectively train a standard supervised Deep Neural Network. Instead, we extract features for each of the images from each of the Fitzpatrick17k-trained networks in Table 2 and use them to train linear Support Vector Machine (SVM) classifiers. This exercise shall evaluate how well each of the trained networks are able to linearly separate malignant/not malignant in an unseen dataset. We train each of the SVMs in five-fold cross validation, with five splits of 80% training and 20% validation. We also evaluate the features of each of the networks trained in the five separate Fitzpatrick17k splits, resulting in 25 total evaluations of DDI per method. in DDI, the Fitzpatrick skin types are grouped into three clusters: I/II, III/IV, and V/VI

VisualDx Internal Dataset: This dataset consists of 130,663 images with three associated labeled tasks. “Expert” diagnosis prediction (E) has the model predict a diagnosis from 269 separate classes. “Consumer” diagnosis prediction (C) is a strict subset of “Expert” diagnosis prediction, with 191 separate classes. Finally, “Lesion” prediction (L) has the model predict lesion morphology from an image, with 80 separate classes. Of the 130,663 images, 86,157 have diagnosis labels and 107,841 have lesion labels (many have both).We evaluate our networks on a single fresh split of 80% training, 10% validation, and 10% test. We first tune the baseline network on the validation set, finding that a ConvNext-Base backbone26 pretrained on ImageNet 22k and ImageNet 1k fits the data best. We train the network for 50 epochs.

",DNN,"We evaluated on the Fitzpatrick17k dataset using 5 random stratified splits (80% training, 20% validation), we compared 6 methods :
      1) BL (EfficientNetB4 with minimal augmentation).
      2) RA (BL + RandAugment).
      3) CO (BL + CutOut).
      4) CO+RA (BL + both CutOut and RandAugment).
      5) Ours (BL + our SoftOtsuNet) and
      6) Ours + RA (Ours + RandAugment).

https://docs.google.com/spreadsheets/d/1FM8H9FhJBOZ7yAqDAuiIyZX7wM19eolcwWXHmUzTcZA/edit?usp=sharing
","In dermatology, the most economical method of gathering images is from commodity cameras used by either clinicians or patients themselves, and this means that irrelevant background information is almost certainly part of the data. Finding and exploiting useful statistical priors about clinical data can open up means of cleaning and augmenting the data in concert with an unsupervised neural network."
From Majority to Minority: A Diffusion-based Augmentation for Underrepresented Groups in Skin Lesion Analysis,"The paper discusses the challenge of AI-based skin cancer diagnosis systems underperforming for minority groups due to insufficient representation in training data. While data collection and annotation for minority groups are ideal solutions, they are costly and time-consuming. The authors propose a diffusion-based augmentation framework that leverages data from majority groups to generate synthetic images, improving diagnostic results for minority groups. Their case study on different skin types shows that this approach can enhance diagnostic accuracy for underrepresented groups, even with minimal reference data. This framework holds practical value in medical imaging, addressing under-diagnosis issues for certain groups.",2024,None,https://arxiv.org/abs/2406.18375,"We conduct our experiments using the Fitzpatrick17k dataset, where each image
 is annotated with a condition and a FitzpatrickSkinType(FST) label. In line
 with,our analysis narrows down to a subset of the Fitzpatrick17k dataset,
 encompassing 7 conditions. These conditions were selected because
 they represent the largest sample sizes at the ends of the Fitzpatrick Skin Type
 (FSTI-IIorV-VI) spectrum. Unlike,our study excludes intermediate skin
 types (FSTIII-IV), to explore the efficacy of our diffusion-based augmentation
 in a more challenging and explainable way. We randomly sample 8 images for
 each condition from the lightest (FSTI-II) and darkest (FSTV-VI) skin type
 groups, resulting in a flexible subset of 56 images for each group.  For classifier backbones,we utilized pre-trained
 VGG-16, ResNet-18, and ViT-B-16 and trained each classifier using the Adam optimizer with an initial learning rate of 1e-3 and transformations",none,Diffusion,https://docs.google.com/spreadsheets/d/1rMzIrLbKbaxsE4dw7FreS3WshGSyMWe6V1ELsGdUMUc/edit?usp=sharing,"While the diffusion-based framework generates synthetic images, the quality and realism of these images might not always match real-world data, potentially affecting the model’s performance. Despite leveraging majority group data, there might still be a domain gap between synthetic images and real images from minority groups, which could impact diagnostic accuracy."
"Towards Trustable Skin Cancer Diagnosis via Rewriting Model’s Decision
                                –Supplemental Material–","In this supplementary material, we provide more details
about datasets, additional training details, network architectures, t-SNE visualisation, concept accuracy, and explanation visualisation.",2023,Conference on Computer Vision and Pattern Recognition (CVPR) 2023,https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yan_Towards_Trustable_Skin_CVPR_2023_supplemental.pdf,"Fitzpatrick17k: Fitzpatrick17k contains 16577 clinical images labeled by 114 skin conditions and 6 Fitzpatrick skin types.
Probe dataset
SKINCON: SKINCON is a skin disease dataset densely annotated by domain experts for fine-grained model debug ging and analysis. It includes 3230 images with 48 clinical concepts, 22 of which have over 50 images.","We choose SynthDerm, ISIC2016, ISIC2017, and ISIC2019_2020 as evaluating datasets in the section “Confounding Concept Discovery"" of the experimental part. We chose Synth Dermas it is a well-controlled dataset and chose other datasets due to their popularity in dermatology. Also, we choose Fitzpatrick17k and DDI as training and testing dataset in the section “ Debiasing the Negative Impact of Skin Tone"" as they contain rich Fitzpatrick skin type labels.", Rewriting Model’s Decision (RMD),https://docs.google.com/spreadsheets/d/1r3CS_kpEmN2Lhr4qQ3nibVjp9lDPEEZmVjM2l4vWP0g/edit?usp=sharing,"The framework requires human intervention to correct the model’s decision logic, which can be time-consuming and may not be feasible in all clinical settings. Its effectiveness across diverse and unseen datasets remains to be fully validated."
Enhancing Skin Disease Detection Accuracy and Fairness: Mitigating Biases in Dermatological Diagnosis Models,"This article focuses on the impact of dataset imbalance on the results of the ResNet18 model and explores methods to
address and mitigate imbalance. For the two types of imbalance in the Fitzpatrick dataset, we employed sampling, simple
augmentation, and DCGAN augmentation to address the imbalance and enhance accuracy and efficiency. Additionally, we examined
the data augmentation effects of DCGAN on both Fitzpatrick and HAM10000 datasets. Based on our experiment results, both simple
and DCGAN augmentation have proven to be effective to mitigate bias in the model.",2023,None,https://www.cs.toronto.edu/~lindell/teaching/2529/past_projects/2023/report/qianyi-li.pdf,"Fitzpatrick with additional Fitzpatrick scale labels. The Fitzpatrick scale is a six-point measurement for sun reactivity of skin phenotype. The dataset includes labels for over 100 skin condi
tions, which are then categorized into nine subgroups, encompassing inflammatory, genodermatoses, and malignant epidermal conditions. These are further consolidated into three overarching categories: benign cancer, malignant cancer, and non-neoplastic (non-cancerous). To simplify and highlight the potential impact of biases within the dataset on model performance, we will combine the two types of cancers to have a binary label: cancerous and non-cancerous.Through an analysis of the dataset, we identified some certain issues, including two types of extremely imbalance and uneven distribution in the content of the images.","HAM10000: Because of the third limitation in Fitzpatrick17k dataset, we introduced the use of another dataset, HAM10000, to assess the capability of using GANs for data augmentation. HAM10000(“Human Against Machine with 10000 training images”) consists of 10015 dermatoscopic images. In HAM10000 are all focused on displaying small patches of skin, in other words, images in HAM10000 adhering to a similar distribution within each subgroup, which is advantageous for GANs to generate high-quality fake mages based on the training set.",ResNet,https://docs.google.com/spreadsheets/d/1Iw7vMAhxwbtWN3xAZXDlJN4ad_4FCnLHZX-TqGv6ue4/edit?usp=sharing,This method imposes higher requirements on the dataset. It necessitates that the images in the dataset follow a similar distribution.
Optimizing skin disease diagnosis harnessing online community data with contrastive learning and clustering techniques,"The study analyzes the use of unannotated dermatology photographs from online forums to aid in skin condition identification. The authors propose a deep learning model that uses contrastive learning to learn generic representations from unlabeled photos before fine-tuning it on coarsely annotated images. Their method identifies 22 prevalent skin illnesses and shows better diagnostic accuracy, especially for underrepresented conditions. The study emphasizes the value of using online community data for early detection and outbreak control in dermatology.",2024,npj Digital Medicine,https://www.nature.com/articles/s41746-024-01014-x,"Given our primary focus on detecting malignant diseases, particularly melanoma as the most severe form of skin cancer, we isolated melanoma from the broader malignancy category, establishing two distinct classes: malignancies and melanoma. Consequently, we formulated a classifier encompassing 24 classes. Images that didn’t match these 24 labels were categorized as ‘others’. Due to the inadequacy of the DDI dataset to form a new class for training, we opted to combine the two datasets together for this experiment. Classes with fewer than 10 images in each dataset are not considered, as such a small sample size can significantly skew the testing performance. To address the knowledge gap within the model, we augmented the filtered training set with 20 images from each category, excluding malignancies and melanoma, sourced from the benchmark dataset. Due to data volume imbalances, we specifically added images from classes containing more than 50 images to ensure adequate numbers for testing. ",DDI,Pre-trained model (No specific model name stated),https://docs.google.com/spreadsheets/d/1uwMdKrDALBVwOzFo52gd4p46L5iIIiooKV93TElUd7I/edit?usp=sharing,None
Improving Mobile-Based Early Skin Disease Diagnosis for Melanin-Rich Skins,"The paper describes the design and development of a mobile application for detecting skin diseases in individuals with dark skin tones using transfer learning on a pre-trained ResNet50v2 model. The model was trained on a diverse dataset, which was filtered, augmented, and preprocessed to ensure representation of melanin-rich skin. A specialized preprocessing pipeline was created to improve performance for darker skin while maintaining accuracy for lighter skin. Four models were trained for different body parts, each achieving an F1-score above 0.8. The mobile app aims to provide accessible early diagnosis for both civilians and medical practitioners.",2023,DeepLearningIndaba 2023 Conference,https://openreview.net/forum?id=qLjD42dGvD,"To ensure that the dataset encompasses a diverse representation of skins, a filtering process was applied to remove most white skin images using YCBCR color ranges, focusing on retaining darker skin tones. The goal was to create a comprehensive dataset that accounts for the wide spectrum of skin tones, with particular emphasis on melanin-rich skins. For skin disease classification, the following diseases were targeted: Acne Vulgaris, Melanoma, Urticaria, Lichen Planus, Scabies, Folliculitis, Squamous Cell Carcinoma, Rosacea, Basal Cell Carcinoma, Psoriasis, and Allergic Contact Dermatitis. After the filtering and cleaning process, each of these disease categories had 300 images. However, such a small dataset size is insufficient for training a robust model effectively.",none,"models were trained using transfer learning to fine
tune ResNet50v2 (CNN model pre-trained on imagenet, which has shown to offer better performance
 in skin disease classification)",https://docs.google.com/spreadsheets/d/1eAOwmtBDxo_fyD0dpCi0b5iyW4cs79hITQiy5Op2F_4/edit?usp=sharing,
Diagnosis of Skin Disease in Moderately to Highly Pigmented Skin by Artificial Intelligence,"The correct diagnosis of skin disease by general practitioners may be affected by skin type. The use of AI, especially that equipped to accurately diagnose conditions in SOC patients, may be a means of improving the diagnostic performance of providers assessing and managing dermatologic conditions. The purpose of this study is to evaluate the effectiveness of AI in identifying and classifying cutaneous disease in patients with Fitzpatrick skin types IV-VI.",2023,Journal of Drugs in Dermatology,https://www.techrxiv.org/doi/full/10.36227/techrxiv.23565417.v1,"Fitzpatrick 17k
The Fitzpatrick 17 database can be accessed online.It contains 16,577 photos of skin lesions from three top level disease categories: benign-neoplastic, malignant-neoplastic, and non-neoplastic.  It excludes 22 categories of skin conditions. These categories were excluded because they were either too broad, too rare, or the photos were of poor quality. The final dataset includes 114 diseases with a range of 53 to 653 photos per skin condition. The Fitzpatrick skin type of each photo was described by a team of human annotators from Scale AI. Labels were determined by the consensus opinion of the annotators, resulting in 72,277 annotations for the entire Fitzpatrick 17 Dataset.18
21-25 A total of 349 photos have a peer-reviewed, specialist-provided diagnosis and 163 of the photos with a peer-reviewed diagnosis are for skin types IV-VI. These 163 photos were selected as test data for our study",none,AI,"The Dataset classified into 3 disease classes (non-neoplastic(75%), benign-neoplastic(14%), malignant-neoplastic(11%)) across Fitzpatrick IV-VI skin types.
(first prediction = Top 1, second prediction = Top 2)

For non-neoplastic conditions :
     Top 1: 90.98% accuracy, Top 2: 94.26% accuracy.
For benign-neoplastic conditions :
     Top 1: 69.57% accuracy, Top 2: 82.61% accuracy.
For malignant-neoplastic conditions :
     Top 1: 77.78% accuracy, Top 2: 83.33% accuracy.

Overall Accuracy : 
     Top 1: 86.50%, Top 2: 93.25%.","uneven distribution of disease classes (75% non-neoplastic, 14% neoplastic-benign, 11% neoplastic-malignant) within the dataset. Furthermore, it is important to consider the classification system itself. In specific cases, classifying skin conditions into non-neoplastic, neoplastic-benign, and neoplastic-malignant may be ambiguous."
