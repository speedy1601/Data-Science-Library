{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from polars import col\n",
    "import numpy as np\n",
    "from time import time\n",
    "from typing import List, Callable\n",
    "from termcolor import colored\n",
    "\n",
    "color_text = lambda text: f\"{'\\033[1;92m'}{text}{'\\033[0m'}\"\n",
    "extra_info = lambda extra='': f\" {color_text(\"-->\")} {extra}\\n{'-' * 120}\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                         Polars Creation From Lists, Dict, Realworld Datasets\n",
    "```js\n",
    "1. In Polars DataFrame you can set the datatype for each column manually by the 'schema={ColumnName: dtype, ColumnName1: dtype...}'.\n",
    "2. But if a column in CSV is a Floating Point, then polars doesn't directly cast the Floating Point to integer.\n",
    "        df = pl.read_csv(\"D:\\\\datasets\\\\temp.csv\", schema_overrides={'Marks': pl.UInt8}, infer_schema_length=10000, ignore_errors=True)\n",
    "        but it make values like 89.87 to null and 45.0 to 45\n",
    "3. And if a column in CSV is an Integer, Polar can cast it to Floating Point but not the Vice Varsa.\n",
    "\n",
    "        BUTT you should not do these CASTING INSIDE 'read_csv'. First read the CSV, then analyze it, see if the max and min val of a column can be changed to for example 'pl.Uint8' or not or maybe we need to round it first? Then with 'pl.with_columns' cast the columns you need and set the new DataFrame back to the DataFrame you wanted to change.\n",
    "\n",
    "        You can do such casting when you create your own small DataFrame, not on the 'real datasets'.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "        1. In Pandas we say df. then all the methods, attributes are shown.. But in polars when we want to do some operations ON ALL THE COLUMNS, we say 'pl.all()'.\n",
    "        2. 'pl.all()' : This is an 'expression' that represents \"all columns selected\" in the DataFrame. You use it when you want to apply a 'transformation or condition' across 'all columns'. Output for pl.all() = * representing All the columns are selected.\n",
    "        3. 'pl.all().is_null()' is another expresson. Output : *.is_null(). It has not executed yet.\n",
    "            - expression = pl.all().is_null()               Assume we have 2 DataFrame, df1, df2.\n",
    "            - To apply the expression 'expression' on df1 we say : 'df1.select(expression)'. Now the 'expression' is applied on 'df1' and will show the output. We can apply this same expression on df2 as well. \n",
    "        \n",
    "        4. 'df.is_duplicated()' : It works ROW WISE. If you want to check duplicate values on each column => 'df.select(pl.all().is_duplicated())'.\n",
    "        5. Some methods like 'count_null()' works on each column but We should respect polars and do p.all() when we want to do some operations on each column.\n",
    "\n",
    "        `Why Polars Uses Expressions`:\n",
    "            - Efficiency: By using expressions, Polars can optimize the query plan and execute operations more efficiently, especially for large datasets.\n",
    "            - Flexibility: This approach allows chaining of transformations and applying them lazily, which can be evaluated only when needed.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Name</th><th>Age</th><th>IQ</th></tr><tr><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Maria0&quot;</td><td>15</td><td>16</td></tr><tr><td>&quot;Maria1&quot;</td><td>18</td><td>19</td></tr><tr><td>&quot;Maria2&quot;</td><td>21</td><td>22</td></tr><tr><td>&quot;Maria3&quot;</td><td>24</td><td>25</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌────────┬─────┬─────┐\n",
       "│ Name   ┆ Age ┆ IQ  │\n",
       "│ ---    ┆ --- ┆ --- │\n",
       "│ str    ┆ i64 ┆ i64 │\n",
       "╞════════╪═════╪═════╡\n",
       "│ Maria0 ┆ 15  ┆ 16  │\n",
       "│ Maria1 ┆ 18  ┆ 19  │\n",
       "│ Maria2 ┆ 21  ┆ 22  │\n",
       "│ Maria3 ┆ 24  ┆ 25  │\n",
       "└────────┴─────┴─────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from lists\n",
    "info = [\n",
    "    ['Maria0', 15, 16],   # every list is a ROW.\n",
    "    ['Maria1', 18, 19],\n",
    "    ['Maria2', 21, 22],\n",
    "    ['Maria3', 24, 25]\n",
    "]\n",
    "#  This \"schema list\" is to define column names. orient means how I want my each list to be, 'row' or 'col'.\n",
    "pl.DataFrame(info, schema=['Name', 'Age', 'IQ'], orient='row', strict=False) # or pl.DataFrame(info, schema={'Name': pl.String, 'Age': pl.UInt8, 'IQ': pl.UInt8}, orient='row', strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Name</th><th>Age</th><th>IQ</th></tr><tr><td>str</td><td>i64</td><td>u8</td></tr></thead><tbody><tr><td>&quot;Maria0&quot;</td><td>15</td><td>16</td></tr><tr><td>&quot;Maria1&quot;</td><td>18</td><td>19</td></tr><tr><td>&quot;Maria2&quot;</td><td>21</td><td>22</td></tr><tr><td>&quot;Maria3&quot;</td><td>24</td><td>25</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌────────┬─────┬─────┐\n",
       "│ Name   ┆ Age ┆ IQ  │\n",
       "│ ---    ┆ --- ┆ --- │\n",
       "│ str    ┆ i64 ┆ u8  │\n",
       "╞════════╪═════╪═════╡\n",
       "│ Maria0 ┆ 15  ┆ 16  │\n",
       "│ Maria1 ┆ 18  ┆ 19  │\n",
       "│ Maria2 ┆ 21  ┆ 22  │\n",
       "│ Maria3 ┆ 24  ┆ 25  │\n",
       "└────────┴─────┴─────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dictionary\n",
    "info = {\n",
    "    'Name' : ['Maria0', 'Maria1', 'Maria2', 'Maria3'],\n",
    "    'Age' : [15, 18, 21, 24],\n",
    "    'IQ' : [16, 19, 22, 25]\n",
    "}\n",
    "#                  The below \"schema/schema_overrides dict\" is for defining the datatype for the columns.\n",
    "pl.DataFrame(info, schema_overrides={'Name': pl.String, 'IQ': pl.UInt8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 9)\n",
      "┌────────────────┬─────────┬────────┬──────────┬───┬────────┬────────┬────────────────┬────────────┐\n",
      "│ Name           ┆ Team    ┆ Number ┆ Position ┆ … ┆ Height ┆ Weight ┆ College        ┆ Salary     │\n",
      "│ ---            ┆ ---     ┆ ---    ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---            ┆ ---        │\n",
      "│ str            ┆ str     ┆ f64    ┆ str      ┆   ┆ str    ┆ f64    ┆ str            ┆ f64        │\n",
      "╞════════════════╪═════════╪════════╪══════════╪═══╪════════╪════════╪════════════════╪════════════╡\n",
      "│ Avery Bradley  ┆ Boston  ┆ 0.0    ┆ PG       ┆ … ┆ 6-2    ┆ 180.0  ┆ Texas          ┆ 7.730337e6 │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "│ Jae Crowder    ┆ Boston  ┆ 99.0   ┆ SF       ┆ … ┆ 6-6    ┆ 235.0  ┆ Marquette      ┆ 6.796117e6 │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "│ John Holland   ┆ Boston  ┆ 30.0   ┆ SG       ┆ … ┆ 6-5    ┆ 205.0  ┆ Boston         ┆ null       │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆ University     ┆            │\n",
      "│ R.J. Hunter    ┆ Boston  ┆ 28.0   ┆ SG       ┆ … ┆ 6-5    ┆ 185.0  ┆ Georgia State  ┆ 1.14864e6  │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "│ Jonas Jerebko  ┆ Boston  ┆ 8.0    ┆ PF       ┆ … ┆ 6-10   ┆ 231.0  ┆ null           ┆ 5e6        │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "│ Amir Johnson   ┆ Boston  ┆ 90.0   ┆ PF       ┆ … ┆ 6-9    ┆ 240.0  ┆ null           ┆ 1.2e7      │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "│ Jordan Mickey  ┆ Boston  ┆ 55.0   ┆ PF       ┆ … ┆ 6-8    ┆ 235.0  ┆ LSU            ┆ 1.17096e6  │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "│ Kelly Olynyk   ┆ Boston  ┆ 41.0   ┆ C        ┆ … ┆ 7-0    ┆ 238.0  ┆ Gonzaga        ┆ 2.16516e6  │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "│ Terry Rozier   ┆ Boston  ┆ 12.0   ┆ PG       ┆ … ┆ 6-2    ┆ 190.0  ┆ Louisville     ┆ 1.82436e6  │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "│ Marcus Smart   ┆ Boston  ┆ 36.0   ┆ PG       ┆ … ┆ 6-4    ┆ 220.0  ┆ Oklahoma State ┆ 3.43104e6  │\n",
      "│                ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆                ┆            │\n",
      "└────────────────┴─────────┴────────┴──────────┴───┴────────┴────────┴────────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# from real world datasets\n",
    "\n",
    "df = pl.read_csv(\"D:\\\\datasets\\\\nba.csv\")\n",
    "# print(df, extra_info())\n",
    "# \n",
    "# df1 = df.with_columns(\n",
    "#     pl.col('Number').ceil().cast(pl.UInt8),\n",
    "#     pl.col('Height')\n",
    "# )\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#              [rows, columns]. rows = columns = `A Single Value i.e. A Scalar Value` OR `can be a List` OR `Slice(:)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 3)\n",
      "┌────────────────┬────────┬─────────┐\n",
      "│ Team           ┆ Height ┆ College │\n",
      "│ ---            ┆ ---    ┆ ---     │\n",
      "│ str            ┆ str    ┆ str     │\n",
      "╞════════════════╪════════╪═════════╡\n",
      "│ Boston Celtics ┆ 6-10   ┆ null    │\n",
      "└────────────────┴────────┴─────────┘  \u001b[1;92m-->\u001b[0m df[4, ['Team', 'Height', 'College']]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (4, 3)\n",
      "┌────────────────┬────────┬───────────────────┐\n",
      "│ Team           ┆ Height ┆ College           │\n",
      "│ ---            ┆ ---    ┆ ---               │\n",
      "│ str            ┆ str    ┆ str               │\n",
      "╞════════════════╪════════╪═══════════════════╡\n",
      "│ Boston Celtics ┆ 6-2    ┆ Texas             │\n",
      "│ Boston Celtics ┆ 6-6    ┆ Marquette         │\n",
      "│ Boston Celtics ┆ 6-5    ┆ Boston University │\n",
      "│ Boston Celtics ┆ 6-5    ┆ Georgia State     │\n",
      "└────────────────┴────────┴───────────────────┘  \u001b[1;92m-->\u001b[0m first 4 rows but only Those 3 columns\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (5, 3)\n",
      "┌────────────────────────┬────────┬────────────────┐\n",
      "│ Team                   ┆ Height ┆ College        │\n",
      "│ ---                    ┆ ---    ┆ ---            │\n",
      "│ str                    ┆ str    ┆ str            │\n",
      "╞════════════════════════╪════════╪════════════════╡\n",
      "│ Boston Celtics         ┆ 6-2    ┆ Texas          │\n",
      "│ Los Angeles Clippers   ┆ 6-0    ┆ Wake Forest    │\n",
      "│ Indiana Pacers         ┆ 6-3    ┆ IUPUI          │\n",
      "│ San Antonio Spurs      ┆ 6-6    ┆ North Carolina │\n",
      "│ Minnesota Timberwolves ┆ 6-11   ┆ null           │\n",
      "└────────────────────────┴────────┴────────────────┘  \u001b[1;92m-->\u001b[0m df[::100, ['Team', 'Height', 'College']]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (458, 4)\n",
      "┌───────────────┬──────────┬────────┬────────────┐\n",
      "│ Name          ┆ Position ┆ Weight ┆ Salary     │\n",
      "│ ---           ┆ ---      ┆ ---    ┆ ---        │\n",
      "│ str           ┆ str      ┆ f64    ┆ f64        │\n",
      "╞═══════════════╪══════════╪════════╪════════════╡\n",
      "│ Avery Bradley ┆ PG       ┆ 180.0  ┆ 7.730337e6 │\n",
      "│ Jae Crowder   ┆ SF       ┆ 235.0  ┆ 6.796117e6 │\n",
      "│ John Holland  ┆ SG       ┆ 205.0  ┆ null       │\n",
      "│ R.J. Hunter   ┆ SG       ┆ 185.0  ┆ 1.14864e6  │\n",
      "│ Jonas Jerebko ┆ PF       ┆ 231.0  ┆ 5e6        │\n",
      "│ …             ┆ …        ┆ …      ┆ …          │\n",
      "│ Shelvin Mack  ┆ PG       ┆ 203.0  ┆ 2.433333e6 │\n",
      "│ Raul Neto     ┆ PG       ┆ 179.0  ┆ 900000.0   │\n",
      "│ Tibor Pleiss  ┆ C        ┆ 256.0  ┆ 2.9e6      │\n",
      "│ Jeff Withey   ┆ C        ┆ 231.0  ┆ 947276.0   │\n",
      "│ null          ┆ null     ┆ null   ┆ null       │\n",
      "└───────────────┴──────────┴────────┴────────────┘  \u001b[1;92m-->\u001b[0m \n",
      "[('Name', np.True_), ('Team', np.False_), ('Number', np.False_), ('Position', np.True_), ('Age', np.False_), ('Height', np.False_), ('Weight', np.True_), ('College', np.False_), ('Salary', np.True_)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#                                            Only for DataFrames, NOT FOR LAZYFRAME\n",
    "\n",
    "print(df[ 4, ['Team', 'Height', 'College']], extra_info(\"df[4, ['Team', 'Height', 'College']]\"))\n",
    "print(df[:4, ['Team', 'Height', 'College']], extra_info(\"first 4 rows but only Those 3 columns\"))\n",
    "print(df[::100, ['Team', 'Height', 'College']], extra_info(\"df[::100, ['Team', 'Height', 'College']]\"))\n",
    "\n",
    "bool_columns = np.random.choice(a=[True, False], size=(df.width,), replace=True)\n",
    "print(df[:, bool_columns], extra_info(f\"\\n{list(zip(df.columns, bool_columns))}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                               `slice()` For LAZYFRAME\n",
    "```js\n",
    "        1. LazyFrame 'lf', where the Tabular Data has not been created until we use 'lf.collect()'. Thats why we cant use stuff like   lf[:17:5, ['name', 'city', 'age']].\n",
    "        2. lf.slice(index, length) => This will only slice 'rows' and returns also lazyframe.\n",
    "        3. lf.select(pl.col( *Columns Name )) => This selects specific 'columns'. Nope, cant use 'Boolean Columns' in '*Columns Name'.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                       DataFrame Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458, 9)  \u001b[1;92m-->\u001b[0m shape\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "['Name', 'Team', 'Number', 'Position', 'Age', 'Height', 'Weight', 'College', 'Salary']    <class 'list'>  \u001b[1;92m-->\u001b[0m column names\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[String, String, Float64, String, Float64, String, Float64, String, Float64]    <class 'list'>  \u001b[1;92m-->\u001b[0m dtypes\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "458    9  \u001b[1;92m-->\u001b[0m heigh and width\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Schema({'Name': String, 'Team': String, 'Number': Float64, 'Position': String, 'Age': Float64, 'Height': String, 'Weight': Float64, 'College': String, 'Salary': Float64}) \n",
      " <class 'polars.schema.Schema'>  \u001b[1;92m-->\u001b[0m Schema(Column Names with their Datatype)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.shape, extra_info(\"shape\"))\n",
    "print(df.columns,'  ', type(df.columns), extra_info(\"column names\"))\n",
    "print(df.dtypes, '  ', type(df.dtypes),  extra_info(\"dtypes\"))\n",
    "print(df.height, '  ', df.width, extra_info(\"heigh and width\"))\n",
    "print(df.schema, '\\n', type(df.schema), extra_info(\"Schema(Column Names with their Datatype)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                       DataFrame Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 9)\n",
      "┌────────┬────────┬─────────┬──────────┬───┬────────┬─────────┬─────────┬─────────┐\n",
      "│ Name   ┆ Team   ┆ Number  ┆ Position ┆ … ┆ Height ┆ Weight  ┆ College ┆ Salary  │\n",
      "│ ---    ┆ ---    ┆ ---     ┆ ---      ┆   ┆ ---    ┆ ---     ┆ ---     ┆ ---     │\n",
      "│ str    ┆ str    ┆ str     ┆ str      ┆   ┆ str    ┆ str     ┆ str     ┆ str     │\n",
      "╞════════╪════════╪═════════╪══════════╪═══╪════════╪═════════╪═════════╪═════════╡\n",
      "│ 1      ┆ 1      ┆ 1       ┆ 1        ┆ … ┆ 1      ┆ 1       ┆ 85      ┆ 12      │\n",
      "│ String ┆ String ┆ Float64 ┆ String   ┆ … ┆ String ┆ Float64 ┆ String  ┆ Float64 │\n",
      "└────────┴────────┴─────────┴──────────┴───┴────────┴─────────┴─────────┴─────────┘  \u001b[1;92m-->\u001b[0m info(Index, Columns, Count of Non Null Values in each column, dtype)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (9, 10)\n",
      "┌────────────┬────────────┬────────────┬───────────┬───┬────────┬────────────┬─────────┬───────────┐\n",
      "│ statistic  ┆ Name       ┆ Team       ┆ Number    ┆ … ┆ Height ┆ Weight     ┆ College ┆ Salary    │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---       ┆   ┆ ---    ┆ ---        ┆ ---     ┆ ---       │\n",
      "│ str        ┆ str        ┆ str        ┆ f64       ┆   ┆ str    ┆ f64        ┆ str     ┆ f64       │\n",
      "╞════════════╪════════════╪════════════╪═══════════╪═══╪════════╪════════════╪═════════╪═══════════╡\n",
      "│ count      ┆ 457        ┆ 457        ┆ 457.0     ┆ … ┆ 457    ┆ 457.0      ┆ 373     ┆ 446.0     │\n",
      "│ null_count ┆ 1          ┆ 1          ┆ 1.0       ┆ … ┆ 1      ┆ 1.0        ┆ 85      ┆ 12.0      │\n",
      "│ mean       ┆ null       ┆ null       ┆ 17.678337 ┆ … ┆ null   ┆ 221.522976 ┆ null    ┆ 4.8427e6  │\n",
      "│ std        ┆ null       ┆ null       ┆ 15.96609  ┆ … ┆ null   ┆ 26.368343  ┆ null    ┆ 5.2292e6  │\n",
      "│ min        ┆ Aaron      ┆ Atlanta    ┆ 0.0       ┆ … ┆ 5-11   ┆ 161.0      ┆ Alabama ┆ 30888.0   │\n",
      "│            ┆ Brooks     ┆ Hawks      ┆           ┆   ┆        ┆            ┆         ┆           │\n",
      "│ 25%        ┆ null       ┆ null       ┆ 5.0       ┆ … ┆ null   ┆ 200.0      ┆ null    ┆ 1.035e6   │\n",
      "│ 50%        ┆ null       ┆ null       ┆ 13.0      ┆ … ┆ null   ┆ 220.0      ┆ null    ┆ 2.84196e6 │\n",
      "│ 75%        ┆ null       ┆ null       ┆ 25.0      ┆ … ┆ null   ┆ 240.0      ┆ null    ┆ 6.5e6     │\n",
      "│ max        ┆ Zaza       ┆ Washington ┆ 99.0      ┆ … ┆ 7-3    ┆ 307.0      ┆ Xavier  ┆ 2.5e7     │\n",
      "│            ┆ Pachulia   ┆ Wizards    ┆           ┆   ┆        ┆            ┆         ┆           │\n",
      "└────────────┴────────────┴────────────┴───────────┴───┴────────┴────────────┴─────────┴───────────┘  \u001b[1;92m-->\u001b[0m describe\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# head, tail, sample are same as series.\n",
    "df_info = lambda: df.null_count().cast(pl.String).vstack( pl.DataFrame(dict(zip(df.columns, map(str, df.dtypes)))) )\n",
    "#                                         Polars doesn't have pandas dataframe.info() so I made it.\n",
    "print(df_info(), extra_info(\"info(Index, Columns, Count of Non Null Values in each column, dtype)\"))\n",
    "print(df.describe(), extra_info(\"describe\")) # works on every column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                 filter / select / with_columns\n",
    "```js\n",
    "        1. df.filter(expression to perform on the df) :\n",
    "                When based on an operation we want to display 'specific columns or specific values from the dataframe OR the entire dataframe', we do filter(..) which returns the ENTIRE New DataFrame but we can select(..) specific columns to display.\n",
    "\n",
    "        2. df.select(list of columns to display OR expression to perform) :\n",
    "                When we want to 'select specific columns to display' OR we want to find the sum()/prod()/mean()/std() etc such CALCULATION on the entire or specific columns OR we want to have only the 'Boolean Mask result', not the actual output, we do select().\n",
    "        \n",
    "        3. df.with_columns(changes on ALL or specific columns seperated by comma) :\n",
    "                Assume we have 10 columns. Now we want to change 2 or 3 columns DataType by 'casting' or change their values and AFTER the changes on specific columns we want to have the ENTIRE DATAFRAME having those changes on those specific columns and the REST UNCHANGED COLUMNS as well. For this we do df.with_columns(). We can even set the new dataframe to the old dataframe.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 9)\n",
      "┌───────────────┬────────────────┬────────┬──────────┬───┬────────┬────────┬─────────┬────────────┐\n",
      "│ Name          ┆ Team           ┆ Number ┆ Position ┆ … ┆ Height ┆ Weight ┆ College ┆ Salary     │\n",
      "│ ---           ┆ ---            ┆ ---    ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---     ┆ ---        │\n",
      "│ str           ┆ str            ┆ f64    ┆ str      ┆   ┆ str    ┆ f64    ┆ str     ┆ f64        │\n",
      "╞═══════════════╪════════════════╪════════╪══════════╪═══╪════════╪════════╪═════════╪════════════╡\n",
      "│ Avery Bradley ┆ Boston Celtics ┆ 0.0    ┆ PG       ┆ … ┆ 6-2    ┆ 180.0  ┆ Texas   ┆ 7.730337e6 │\n",
      "└───────────────┴────────────────┴────────┴──────────┴───┴────────┴────────┴─────────┴────────────┘ \n",
      "\n",
      "shape: (458,)\n",
      "Series: 'Name' [bool]\n",
      "[\n",
      "\ttrue\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\t…\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tnull\n",
      "] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Name</th><th>Team</th><th>Number</th><th>Position</th><th>Age</th><th>Height</th><th>Weight</th><th>College</th><th>Salary</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>457</td><td>457</td><td>457</td><td>457</td><td>457</td><td>457</td><td>457</td><td>373</td><td>446</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 9)\n",
       "┌──────┬──────┬────────┬──────────┬───┬────────┬────────┬─────────┬────────┐\n",
       "│ Name ┆ Team ┆ Number ┆ Position ┆ … ┆ Height ┆ Weight ┆ College ┆ Salary │\n",
       "│ ---  ┆ ---  ┆ ---    ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---     ┆ ---    │\n",
       "│ u32  ┆ u32  ┆ u32    ┆ u32      ┆   ┆ u32    ┆ u32    ┆ u32     ┆ u32    │\n",
       "╞══════╪══════╪════════╪══════════╪═══╪════════╪════════╪═════════╪════════╡\n",
       "│ 457  ┆ 457  ┆ 457    ┆ 457      ┆ … ┆ 457    ┆ 457    ┆ 373     ┆ 446    │\n",
       "└──────┴──────┴────────┴──────────┴───┴────────┴────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.filter( pl.col('Name').str.contains('Avery') ), '\\n')\n",
    "df.filter( pl.col('Name').str.contains('Avery') ).select(['Name', 'Height']) # YOU CAN'T WRITE df.filter( pl.col('Name').str.contains('Avery').select(['Name', 'Height']) )\n",
    "\n",
    "mask = df.select(pl.col('Name').str.contains('Avery')).to_series()\n",
    "print(mask, '\\n')\n",
    "\n",
    "df.select(pl.all().count()) # won't work if you write filter instead of select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                        filter()\n",
    "```js\n",
    "        1. df.filter(conditions seperated by comma) : It returns the Whole New DataFrame after applying the filter on 'df'. But if you want specific columns => df.filter(conditions seperated by comma).select([column names]) or df.filter(conditions seperated by comma)[[column names]]\n",
    "\n",
    "        2. df.lazy().filter(conditions seperated by comma) : Polars known for laziness and it gives FASTER EXECUTION reducing the unnecessery operations which occurs INTERNALLY like :\n",
    "\n",
    "            df.filter(conditions seperated by comma) returns the whole DataFrame and then with .select([column names]), it gives us the specfic columns. BUT\n",
    "            in df.lazy().filter(conditions seperated by comma).select([column names]) : polars doesn't even return the whole new dataframe when we do 'df.filter(..)' because polars see that we selected only specific columns by '.select([..])', so it directly returns only those specific columns we selected after 'df.filter(..)'.' Thats why it RUNS FASTER!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0050618648529052734\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "pp = df.filter(pl.col('Number') > 50).select(['Name', 'Age'])\n",
    "print(time() - start)\n",
    "# pp[0, 'Name'] = 'AAAAA'\n",
    "# print(pp['Name'][0], df['Name'][0]) # AAAAA, Avery Bradley. I.E. pp is not a view but A NEW DataFrame\n",
    "\n",
    "start = time()\n",
    "pp1 = df.lazy().filter(pl.col('Number') > 50).select(['Name', 'Age']).collect()\n",
    "print(time() - start) # Always do lazy operation\n",
    "# pp1[0, 'Name'] = 'AAAAA'\n",
    "# print(pp1['Name'][0], df['Name'][0]) # AAAAA, Avery Bradley. I.E. pp1 is not a view but A NEW DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Name</th><th>Team</th><th>Number</th><th>Position</th><th>Age</th><th>Height</th><th>Weight</th><th>College</th><th>Salary</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Avery Bradley&quot;</td><td>&quot;Boston Celtics&quot;</td><td>0.0</td><td>&quot;PG&quot;</td><td>25.0</td><td>&quot;6-2&quot;</td><td>180.0</td><td>&quot;Texas&quot;</td><td>7.730337e6</td></tr><tr><td>&quot;Jae Crowder&quot;</td><td>&quot;Boston Celtics&quot;</td><td>99.0</td><td>&quot;SF&quot;</td><td>25.0</td><td>&quot;6-6&quot;</td><td>235.0</td><td>&quot;Marquette&quot;</td><td>6.796117e6</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "┌───────────────┬─────────┬────────┬──────────┬───┬────────┬────────┬───────────┬────────────┐\n",
       "│ Name          ┆ Team    ┆ Number ┆ Position ┆ … ┆ Height ┆ Weight ┆ College   ┆ Salary     │\n",
       "│ ---           ┆ ---     ┆ ---    ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---       ┆ ---        │\n",
       "│ str           ┆ str     ┆ f64    ┆ str      ┆   ┆ str    ┆ f64    ┆ str       ┆ f64        │\n",
       "╞═══════════════╪═════════╪════════╪══════════╪═══╪════════╪════════╪═══════════╪════════════╡\n",
       "│ Avery Bradley ┆ Boston  ┆ 0.0    ┆ PG       ┆ … ┆ 6-2    ┆ 180.0  ┆ Texas     ┆ 7.730337e6 │\n",
       "│               ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆           ┆            │\n",
       "│ Jae Crowder   ┆ Boston  ┆ 99.0   ┆ SF       ┆ … ┆ 6-6    ┆ 235.0  ┆ Marquette ┆ 6.796117e6 │\n",
       "│               ┆ Celtics ┆        ┆          ┆   ┆        ┆        ┆           ┆            │\n",
       "└───────────────┴─────────┴────────┴──────────┴───┴────────┴────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                   rename(), is_duplicated(), null_count(), is_null()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (458, 9)\n",
      "┌────────────────┬───────────┬───────┬──────────┬───┬────────┬────────┬───────────────┬────────────┐\n",
      "│ Name           ┆ Team      ┆ Marks ┆ Position ┆ … ┆ Height ┆ Weight ┆ College       ┆ Wage       │\n",
      "│ ---            ┆ ---       ┆ ---   ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---           ┆ ---        │\n",
      "│ str            ┆ str       ┆ f64   ┆ str      ┆   ┆ str    ┆ f64    ┆ str           ┆ f64        │\n",
      "╞════════════════╪═══════════╪═══════╪══════════╪═══╪════════╪════════╪═══════════════╪════════════╡\n",
      "│ Avery Bradley  ┆ Boston    ┆ 0.0   ┆ PG       ┆ … ┆ 6-2    ┆ 180.0  ┆ Texas         ┆ 7.730337e6 │\n",
      "│                ┆ Celtics   ┆       ┆          ┆   ┆        ┆        ┆               ┆            │\n",
      "│ Jae Crowder    ┆ Boston    ┆ 99.0  ┆ SF       ┆ … ┆ 6-6    ┆ 235.0  ┆ Marquette     ┆ 6.796117e6 │\n",
      "│                ┆ Celtics   ┆       ┆          ┆   ┆        ┆        ┆               ┆            │\n",
      "│ John Holland   ┆ Boston    ┆ 30.0  ┆ SG       ┆ … ┆ 6-5    ┆ 205.0  ┆ Boston        ┆ null       │\n",
      "│                ┆ Celtics   ┆       ┆          ┆   ┆        ┆        ┆ University    ┆            │\n",
      "│ R.J. Hunter    ┆ Boston    ┆ 28.0  ┆ SG       ┆ … ┆ 6-5    ┆ 185.0  ┆ Georgia State ┆ 1.14864e6  │\n",
      "│                ┆ Celtics   ┆       ┆          ┆   ┆        ┆        ┆               ┆            │\n",
      "│ Jonas Jerebko  ┆ Boston    ┆ 8.0   ┆ PF       ┆ … ┆ 6-10   ┆ 231.0  ┆ null          ┆ 5e6        │\n",
      "│                ┆ Celtics   ┆       ┆          ┆   ┆        ┆        ┆               ┆            │\n",
      "│ …              ┆ …         ┆ …     ┆ …        ┆ … ┆ …      ┆ …      ┆ …             ┆ …          │\n",
      "│ Shelvin Mack   ┆ Utah Jazz ┆ 8.0   ┆ PG       ┆ … ┆ 6-3    ┆ 203.0  ┆ Butler        ┆ 2.433333e6 │\n",
      "│ Raul Neto      ┆ Utah Jazz ┆ 25.0  ┆ PG       ┆ … ┆ 6-1    ┆ 179.0  ┆ null          ┆ 900000.0   │\n",
      "│ Tibor Pleiss   ┆ Utah Jazz ┆ 21.0  ┆ C        ┆ … ┆ 7-3    ┆ 256.0  ┆ null          ┆ 2.9e6      │\n",
      "│ Jeff Withey    ┆ Utah Jazz ┆ 24.0  ┆ C        ┆ … ┆ 7-0    ┆ 231.0  ┆ Kansas        ┆ 947276.0   │\n",
      "│ null           ┆ null      ┆ null  ┆ null     ┆ … ┆ null   ┆ null   ┆ null          ┆ null       │\n",
      "└────────────────┴───────────┴───────┴──────────┴───┴────────┴────────┴───────────────┴────────────┘  \u001b[1;92m-->\u001b[0m RENAMING SPECIFIC COLUMNS\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (458,)\n",
      "Series: '' [bool]\n",
      "[\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\t…\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "\tfalse\n",
      "]\n",
      "shape: (1, 9)\n",
      "┌──────┬──────┬────────┬──────────┬───┬────────┬────────┬─────────┬────────┐\n",
      "│ Name ┆ Team ┆ Number ┆ Position ┆ … ┆ Height ┆ Weight ┆ College ┆ Salary │\n",
      "│ ---  ┆ ---  ┆ ---    ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---     ┆ ---    │\n",
      "│ u32  ┆ u32  ┆ u32    ┆ u32      ┆   ┆ u32    ┆ u32    ┆ u32     ┆ u32    │\n",
      "╞══════╪══════╪════════╪══════════╪═══╪════════╪════════╪═════════╪════════╡\n",
      "│ 1    ┆ 1    ┆ 1      ┆ 1        ┆ … ┆ 1      ┆ 1      ┆ 85      ┆ 12     │\n",
      "└──────┴──────┴────────┴──────────┴───┴────────┴────────┴─────────┴────────┘  \u001b[1;92m-->\u001b[0m count nulls on Each COLUMN.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (458, 9)\n",
      "┌───────┬───────┬────────┬──────────┬───┬────────┬────────┬─────────┬────────┐\n",
      "│ Name  ┆ Team  ┆ Number ┆ Position ┆ … ┆ Height ┆ Weight ┆ College ┆ Salary │\n",
      "│ ---   ┆ ---   ┆ ---    ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---     ┆ ---    │\n",
      "│ bool  ┆ bool  ┆ bool   ┆ bool     ┆   ┆ bool   ┆ bool   ┆ bool    ┆ bool   │\n",
      "╞═══════╪═══════╪════════╪══════════╪═══╪════════╪════════╪═════════╪════════╡\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ false   ┆ false  │\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ false   ┆ false  │\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ false   ┆ true   │\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ false   ┆ false  │\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ true    ┆ false  │\n",
      "│ …     ┆ …     ┆ …      ┆ …        ┆ … ┆ …      ┆ …      ┆ …       ┆ …      │\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ false   ┆ false  │\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ true    ┆ false  │\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ true    ┆ false  │\n",
      "│ false ┆ false ┆ false  ┆ false    ┆ … ┆ false  ┆ false  ┆ false   ┆ false  │\n",
      "│ true  ┆ true  ┆ true   ┆ true     ┆ … ┆ true   ┆ true   ┆ true    ┆ true   │\n",
      "└───────┴───────┴────────┴──────────┴───┴────────┴────────┴─────────┴────────┘  \u001b[1;92m-->\u001b[0m Boolean DataFrame after is_null() applied on each column\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (1, 9)\n",
      "┌──────┬──────┬────────┬──────────┬───┬────────┬────────┬─────────┬────────┐\n",
      "│ Name ┆ Team ┆ Number ┆ Position ┆ … ┆ Height ┆ Weight ┆ College ┆ Salary │\n",
      "│ ---  ┆ ---  ┆ ---    ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---     ┆ ---    │\n",
      "│ u32  ┆ u32  ┆ u32    ┆ u32      ┆   ┆ u32    ┆ u32    ┆ u32     ┆ u32    │\n",
      "╞══════╪══════╪════════╪══════════╪═══╪════════╪════════╪═════════╪════════╡\n",
      "│ 1    ┆ 1    ┆ 1      ┆ 1        ┆ … ┆ 1      ┆ 1      ┆ 85      ┆ 12     │\n",
      "└──────┴──────┴────────┴──────────┴───┴────────┴────────┴─────────┴────────┘  \u001b[1;92m-->\u001b[0m 'pl.all().is_null().sum()' applied on each column\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (1, 9)\n",
      "┌──────┬──────┬────────┬──────────┬───┬────────┬────────┬─────────┬────────┐\n",
      "│ Name ┆ Team ┆ Number ┆ Position ┆ … ┆ Height ┆ Weight ┆ College ┆ Salary │\n",
      "│ ---  ┆ ---  ┆ ---    ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---     ┆ ---    │\n",
      "│ bool ┆ bool ┆ bool   ┆ bool     ┆   ┆ bool   ┆ bool   ┆ bool    ┆ bool   │\n",
      "╞══════╪══════╪════════╪══════════╪═══╪════════╪════════╪═════════╪════════╡\n",
      "│ true ┆ true ┆ true   ┆ true     ┆ … ┆ true   ┆ true   ┆ true    ┆ true   │\n",
      "└──────┴──────┴────────┴──────────┴───┴────────┴────────┴─────────┴────────┘  \u001b[1;92m-->\u001b[0m Columns having at least One Null Value = True, else False\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.columns = np.arange(10, df.width+10, dtype='u8').astype('str') # it will change the column names PERMANENTLY.\n",
    "print(df.rename({'Number' : 'Marks', 'Salary' : 'Wage'}), extra_info(\"RENAMING SPECIFIC COLUMNS\"))\n",
    "\n",
    "print(df.is_duplicated()) # returns a Boolean Mask i.e. SERIES. True = That row is DUPLICATED.\n",
    "print(df.null_count(), extra_info(\"count nulls on Each COLUMN.\")) # count nulls on Each COLUMN.\n",
    "\n",
    "# DataFrame doesn't have isnull(), only Series has isnull(). So with select(..) traverse EACH COLUMN/SERIES and apply isnull().\n",
    "print(df.select( pl.all().is_null() ), extra_info(\"Boolean DataFrame after is_null() applied on each column\"))\n",
    "print(df.select( pl.all().is_null().sum() ), extra_info(\"'pl.all().is_null().sum()' applied on each column\"))\n",
    "\n",
    "print(df.select( pl.all().has_nulls() ), extra_info(\"Columns having at least One Null Value = True, else False\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                               drop_nulls() on DataFrame\n",
    "```js\n",
    "        Polars.drop_nulls() traverse through each column i.e. vertically i.e. 'ROW-wise' and while traversing vertically if polars see a column's value is Null, it delete that 'ROW'.' So at the end in the result DataFrame you won't see a single ROW which has any Null value.\n",
    "\n",
    "        'pandas drop_na(subset, axis=1 or 0, how='any' or 'all')' has these 3 important parameters which is really really beneficial. Polars drop_nulls() equivalent to Pandas drop_na(subset, axis=0, how='any'). So I created below after the next block, 'drop_nulls(lazyframe, subset, drop='rows' or 'columns', how='any' or 'all')'.\n",
    "\n",
    "------> Dealing with 'drop=rows':\n",
    "        -------------------------\n",
    "                We want to delete 'WHOLE ROW', means doesnt matter if we want to drop_nulls() based on specific columns or all the columns. E.G.\n",
    "\n",
    "                        True      False       True        True   True                              True\n",
    "                        False     False       False       False  False         =>                  False\n",
    "                        True      True        True        True   True                              True\n",
    "                        ---------------------------      --------------              -------------------------------------\n",
    "                             pl.all().is_null()       pl.col(subset).is_null()       pl.any_horizontal( on both left df)\n",
    "\n",
    "                                                                                     = For both left Boolean DataFrame, The Output is same AND 'Both Giving OUTPUT in A Series i.e. A SINGLE COLUMN (NOT 1D array like [True, False. True])'. We can use this SINGLE COLUMN to filter('filter works only on A SERIES/A SINGLE COLUMN BOOLEAN MASK') the ROWS we want.\n",
    "                                                                                     Of course True = It has NULLS and we dont want that row. So ~pl.any_horizontal().\n",
    "------> Dealing with 'drop=columns':\n",
    "        ----------------------------\n",
    "                We want to delete 'WHOLE COLUMN'.\n",
    "\n",
    "                        True      False       True                                   \n",
    "                        False     False       False              =>                  \n",
    "                        True      False       True                              True    False   True\n",
    "                        ---------------------------                    -------------------------------------\n",
    "                             pl.all().is_null()                                 pl.all().is_null().any() (Result : (1, 3) DataFrame)\n",
    "\n",
    "                                                                       = We cant use A Single Row DataFrame as A Boolean Mask. You may think to use `df[0]` to select the Single Row BUT 'if we select just A SINGLE ROW, polars still give us a DataFrame with that single row having column names above'. For this use '.row(index=0)' which 'returns a 1D tuple'. Since we want to delete `COLUMNS` i.e. FILTER 'COLUMNS', filter() wont help us (as filter() filters 'ROWS' only) BUT 'lazyframe.collect()[:, boolean mask or column names], lazyframe.select(pl.col(column names))' will.\n",
    "\n",
    "                                                                       We can use a 1D tuple e.g. [True, False, True] to select columns like 'lazyframe.collect()[:, [True, False, True]]' BUT we dont want to do 'lazyframe.collect()' to filter specific columns, its expensive. So we need to 'find the column names' and pass it to 'lazyframe.select(pl.col(..Here..))'. \n",
    "                                                                       zip(('name', True), ('toy', False), ('born', True)) => Now we can 'find the column names'.\n",
    "\n",
    "                        True      False                                     \n",
    "                        False     False               =>                  \n",
    "                        True      False                           True    False\n",
    "                        ---------------------------        ------------------------------\n",
    "                          pl.col(subset).is_null()         pl.all().is_null().any() (Result : (1, 3) DataFrame)\n",
    "\n",
    "                                                           = Since we are using 'subset' means finding the columns name for [True, False] wont work as 'WE NEED THE OTHER COLUMNS also in the result Data/Lazy-Frame which is not selected in the subset'.\n",
    "\n",
    "                                                           'bool_columns_dict' = {subset[0] : True, subset[1] : False}.\n",
    "                                                           Now we traverse the LazyFrames.columns Name 'SERIALLY' and check if the current columnName is in the 'set(subset)':\n",
    "                                                                        if in the set(subset) => bool_columns_dict[columnname]\n",
    "                                                                        else => 'False' means this columns 'doesnt have anY null'.\n",
    "                                                           By doing this we will get the 'WHOLE 1D BOOLEAN ROW' and we can use it to select columns by passing the columns in 'lazyframe.select(pl.col(..Here..))'\n",
    "        \n",
    "        Note :  pl.all() denoted we selected all the columns.\n",
    "                pl.all().is_null().all() => The last 'all()' does 'BITWISE AND OPERATION' on 'EACH BOOLEAN COLUMN'. THE LAST 'all()' IS NOT 'pl.all()' (which selects all the columns) but 'DATA/LAZY-FRAME.all()' (which does bitwise operation on each column).\n",
    "\n",
    "                expression = pl.all().is_null()\n",
    "                pl.any_horizontal(expression) means 'HORIZONTALLY BITWISE OR OPERATION ON THE ENTIRE DATA/LAZY-FRAME'. `It doesn't mean we are selecting rows to do is_null() row by row`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>toy</th><th>born</th></tr><tr><td>str</td><td>str</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfred&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;Batman&quot;</td><td>&quot;Batmobile&quot;</td><td>1940-04-25</td></tr><tr><td>&quot;Catwoman&quot;</td><td>&quot;Bullwhip&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌──────────┬───────────┬────────────┐\n",
       "│ name     ┆ toy       ┆ born       │\n",
       "│ ---      ┆ ---       ┆ ---        │\n",
       "│ str      ┆ str       ┆ date       │\n",
       "╞══════════╪═══════════╪════════════╡\n",
       "│ Alfred   ┆ null      ┆ null       │\n",
       "│ Batman   ┆ Batmobile ┆ 1940-04-25 │\n",
       "│ Catwoman ┆ Bullwhip  ┆ null       │\n",
       "└──────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop = pl.LazyFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
    "                        \"toy\" : [None, 'Batmobile', 'Bullwhip'],\n",
    "                        \"born\": [None, '1940-4-25', None]})\n",
    "\n",
    "df_drop = df_drop.with_columns(pl.col('born').str.to_date()) # or ....to_datetime() if you also have time.\n",
    "df_drop.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nulls(lazyframe:pl.LazyFrame = None, subset:str|List[str] = None, drop:str = 'rows', how:str = 'any', outputType:str= 'lf') -> pl.LazyFrame|pl.DataFrame:\n",
    "    \"\"\"\n",
    "        1. input_lazyframe = A LazyFrame. default = None\n",
    "        2. subset = A Column Name or A List of \"Column Names\". default = None, means All Columns Selected.\n",
    "        3. drop = 'rows' means Delete ROWS.\n",
    "           drop = 'columns means Delete COLUMNS. default = 'rows'.\n",
    "        4. how = 'any' or 'all'. by default how = 'any'.\n",
    "        4. outputType = 'lf' = LazyFrame or\n",
    "                        'df' = DataFrame.\n",
    "    \"\"\"\n",
    "    all_column_names = np.array(lazyframe.collect_schema().names())\n",
    "\n",
    "    if drop == 'rows':\n",
    "        pl_all_or_subset = pl.all() if subset == None else pl.col(subset)\n",
    "        expression: pl.Expr = pl.any_horizontal(pl_all_or_subset.is_null()) if how == 'any' else pl.all_horizontal(pl_all_or_subset.is_null())\n",
    "        lazy_output = lazyframe.filter(~expression)\n",
    "\n",
    "        return lazy_output if outputType == 'lf' else lazy_output.collect()\n",
    "    \n",
    "    else: # drop == 'columns'\n",
    "        if subset == None or len(subset) == 0:\n",
    "            expression: pl.Expr = pl.all().is_null().any() if how == 'any' else pl.all().is_null().all()\n",
    "            bool_columns = lazyframe.select(expression).collect().row(0)  # (False, True, True, True)\n",
    "            selected_columns = (colName for colName, true in zip(all_column_names, bool_columns) if not true)\n",
    "            lazy_output = lazyframe.select(pl.col(selected_columns))\n",
    "\n",
    "            return lazy_output if outputType == 'lf' else lazy_output.collect()\n",
    "        \n",
    "        else: #\n",
    "            subset_set = set(subset) if subset != None else None\n",
    "            expression: pl.Expr = pl.col(subset).is_null().any() if how == 'any' else pl.col(subset).is_null().all()\n",
    "            bool_columns = lazyframe.select(expression).collect().row(0)  # (False, True)\n",
    "\n",
    "            bool_columns_dict = dict(zip(subset, bool_columns))\n",
    "            whole_bool_columns = (bool_columns_dict[colName] if colName in subset_set else False for colName in all_column_names)\n",
    "\n",
    "            selected_columns = (colName for colName, true in zip(all_column_names, whole_bool_columns) if not true)\n",
    "            lazy_output = lazyframe.select(pl.col(selected_columns))\n",
    "\n",
    "            return lazy_output if outputType == 'lf' else lazy_output.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌──────────┬───────────┬────────────┐\n",
      "│ name     ┆ toy       ┆ born       │\n",
      "│ ---      ┆ ---       ┆ ---        │\n",
      "│ str      ┆ str       ┆ date       │\n",
      "╞══════════╪═══════════╪════════════╡\n",
      "│ Alfred   ┆ null      ┆ null       │\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       │\n",
      "└──────────┴───────────┴────────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mdf_drop\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (1, 3)\n",
      "┌────────┬───────────┬────────────┐\n",
      "│ name   ┆ toy       ┆ born       │\n",
      "│ ---    ┆ ---       ┆ ---        │\n",
      "│ str    ┆ str       ┆ date       │\n",
      "╞════════╪═══════════╪════════════╡\n",
      "│ Batman ┆ Batmobile ┆ 1940-04-25 │\n",
      "└────────┴───────────┴────────────┘  \u001b[1;92m-->\u001b[0m drop_nulls(drop='rows', how='any')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌──────────┬───────────┬────────────┐\n",
      "│ name     ┆ toy       ┆ born       │\n",
      "│ ---      ┆ ---       ┆ ---        │\n",
      "│ str      ┆ str       ┆ date       │\n",
      "╞══════════╪═══════════╪════════════╡\n",
      "│ Alfred   ┆ null      ┆ null       │\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       │\n",
      "└──────────┴───────────┴────────────┘  \u001b[1;92m-->\u001b[0m drop_nulls(drop='rows', how='all')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌──────────┬───────────┬────────────┐\n",
      "│ name     ┆ toy       ┆ born       │\n",
      "│ ---      ┆ ---       ┆ ---        │\n",
      "│ str      ┆ str       ┆ date       │\n",
      "╞══════════╪═══════════╪════════════╡\n",
      "│ Alfred   ┆ null      ┆ null       │\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       │\n",
      "└──────────┴───────────┴────────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mdf_drop\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (2, 3)\n",
      "┌──────────┬───────────┬────────────┐\n",
      "│ name     ┆ toy       ┆ born       │\n",
      "│ ---      ┆ ---       ┆ ---        │\n",
      "│ str      ┆ str       ┆ date       │\n",
      "╞══════════╪═══════════╪════════════╡\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       │\n",
      "└──────────┴───────────┴────────────┘  \u001b[1;92m-->\u001b[0m drop_nulls(subset=['name', 'toy'], drop='rows', how='any')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌──────────┬───────────┬────────────┐\n",
      "│ name     ┆ toy       ┆ born       │\n",
      "│ ---      ┆ ---       ┆ ---        │\n",
      "│ str      ┆ str       ┆ date       │\n",
      "╞══════════╪═══════════╪════════════╡\n",
      "│ Alfred   ┆ null      ┆ null       │\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       │\n",
      "└──────────┴───────────┴────────────┘  \u001b[1;92m-->\u001b[0m drop_nulls(subset=['name', 'toy'], drop='rows', how='all')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 4)\n",
      "┌──────────┬───────────┬────────────┬──────────┐\n",
      "│ name     ┆ toy       ┆ born       ┆ ALL_NULL │\n",
      "│ ---      ┆ ---       ┆ ---        ┆ ---      │\n",
      "│ str      ┆ str       ┆ date       ┆ null     │\n",
      "╞══════════╪═══════════╪════════════╪══════════╡\n",
      "│ Alfred   ┆ null      ┆ null       ┆ null     │\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 ┆ null     │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       ┆ null     │\n",
      "└──────────┴───────────┴────────────┴──────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mdf_drop\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 1)\n",
      "┌──────────┐\n",
      "│ name     │\n",
      "│ ---      │\n",
      "│ str      │\n",
      "╞══════════╡\n",
      "│ Alfred   │\n",
      "│ Batman   │\n",
      "│ Catwoman │\n",
      "└──────────┘  \u001b[1;92m-->\u001b[0m drop_nulls(drop='columns', how='any')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌──────────┬───────────┬────────────┐\n",
      "│ name     ┆ toy       ┆ born       │\n",
      "│ ---      ┆ ---       ┆ ---        │\n",
      "│ str      ┆ str       ┆ date       │\n",
      "╞══════════╪═══════════╪════════════╡\n",
      "│ Alfred   ┆ null      ┆ null       │\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       │\n",
      "└──────────┴───────────┴────────────┘  \u001b[1;92m-->\u001b[0m drop_nulls(drop='columns', how='all')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 4)\n",
      "┌──────────┬───────────┬────────────┬──────────┐\n",
      "│ name     ┆ toy       ┆ born       ┆ ALL_NULL │\n",
      "│ ---      ┆ ---       ┆ ---        ┆ ---      │\n",
      "│ str      ┆ str       ┆ date       ┆ null     │\n",
      "╞══════════╪═══════════╪════════════╪══════════╡\n",
      "│ Alfred   ┆ null      ┆ null       ┆ null     │\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 ┆ null     │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       ┆ null     │\n",
      "└──────────┴───────────┴────────────┴──────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mdf_drop\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌──────────┬────────────┬──────────┐\n",
      "│ name     ┆ born       ┆ ALL_NULL │\n",
      "│ ---      ┆ ---        ┆ ---      │\n",
      "│ str      ┆ date       ┆ null     │\n",
      "╞══════════╪════════════╪══════════╡\n",
      "│ Alfred   ┆ null       ┆ null     │\n",
      "│ Batman   ┆ 1940-04-25 ┆ null     │\n",
      "│ Catwoman ┆ null       ┆ null     │\n",
      "└──────────┴────────────┴──────────┘  \u001b[1;92m-->\u001b[0m drop_nulls(subset=['toy', 'name'], drop='columns', how='any')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌──────────┬───────────┬────────────┐\n",
      "│ name     ┆ toy       ┆ born       │\n",
      "│ ---      ┆ ---       ┆ ---        │\n",
      "│ str      ┆ str       ┆ date       │\n",
      "╞══════════╪═══════════╪════════════╡\n",
      "│ Alfred   ┆ null      ┆ null       │\n",
      "│ Batman   ┆ Batmobile ┆ 1940-04-25 │\n",
      "│ Catwoman ┆ Bullwhip  ┆ null       │\n",
      "└──────────┴───────────┴────────────┘  \u001b[1;92m-->\u001b[0m drop_nulls(subset=['ALL_NULL', 'toy'], drop='columns', how='all')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_drop.collect(), extra_info(color_text(\"df_drop\")))\n",
    "\n",
    "print(drop_nulls(df_drop, drop='rows', how='any', outputType='df'), extra_info(\"drop_nulls(drop='rows', how='any')\"))\n",
    "print(drop_nulls(df_drop, drop='rows', how='all', outputType='df'), extra_info(\"drop_nulls(drop='rows', how='all')\"))\n",
    "\n",
    "print(df_drop.collect(), extra_info(color_text(\"df_drop\")))\n",
    "\n",
    "print(drop_nulls(df_drop, subset=['name', 'toy'], drop='rows', how='any', outputType='df'), extra_info(\"drop_nulls(subset=['name', 'toy'], drop='rows', how='any')\"))\n",
    "print(drop_nulls(df_drop, subset=['name', 'toy'], drop='rows', how='all', outputType='df'), extra_info(\"drop_nulls(subset=['name', 'toy'], drop='rows', how='all')\"))\n",
    "\n",
    "df_drop = df_drop.with_columns(ALL_NULL = None) # New Column 'ALL_NULL' with all null values.\n",
    "print(df_drop.collect(), extra_info(color_text(\"df_drop\")))\n",
    "\n",
    "print(drop_nulls(df_drop, drop='columns', how='any', outputType='df'), extra_info(\"drop_nulls(drop='columns', how='any')\"))\n",
    "print(drop_nulls(df_drop, drop='columns', how='all', outputType='df'), extra_info(\"drop_nulls(drop='columns', how='all')\"))\n",
    "\n",
    "print(df_drop.collect(), extra_info(color_text(\"df_drop\")))\n",
    "print(drop_nulls(df_drop, subset=['toy', 'name'], drop='columns', how='any', outputType='df'), extra_info(\"drop_nulls(subset=['toy', 'name'], drop='columns', how='any')\"))\n",
    "print(drop_nulls(df_drop, subset=['ALL_NULL', 'toy'], drop='columns', how='all', outputType='df'), extra_info(\"drop_nulls(subset=['ALL_NULL', 'toy'], drop='columns', how='all')\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#       drop_duplicates() = unique(subset, keep=`first` or `last`, maintain_order), approx_n_unique().\n",
    "```js\n",
    "        1. pandas drop_duplicates(subset, keep) is the same as polars 'unique(subset, keep=`first` or `last`, maintain_order)'.\n",
    "        2. unique(subset=None, keep='first', maintain_order=False) by default. And by default it returns 'unique rows DataFrame'. It doesnt work on Delete Duplicate 'columns', only on 'rows'.\n",
    "        3.\n",
    "        'keep'='first' : Among [1, 1, 3, 2, 1] it keeps the 'first' 1 and delete its next duplicate 1s.\n",
    "              ='last'  : .................................. 'last'  1 .............. previous duplicate 1s.\n",
    "        \n",
    "        'subset'= A Single Column Name OR LIST of columns names based on what we want to delete duplicate rows :\n",
    "                Lets say among ['name', 'age', 'marks', 'city'] I want to delete those rows whose 'name' and 'marks' are duplicated, doesnt matter if their 'age' and 'city' are also same or not. So drop_duplicates(subset=['name', 'marks'])\n",
    "        \n",
    "        'maintain_order'= After getting the unique rows, do you want to maintain the ORIGINAL ORDER ('True') or ANY RANDOM ORDER ('False').\n",
    "\n",
    "        Note: print(df.select(pl.all().unique())) => won't work because Each Column doesn't have Same Number of Unique Values, so can't ----- form a DatFrame with unmatched number of columns i.e. A column has 4 unique values, another column has 5 unique values, unmatched number of columns can't create a DataFrame.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────┬───────┬────────┬─────┐\n",
      "│ name  ┆ marks ┆ city   ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---    ┆ --- │\n",
      "│ str   ┆ i64   ┆ str    ┆ i64 │\n",
      "╞═══════╪═══════╪════════╪═════╡\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Maria ┆ 79    ┆ Khulna ┆ 25  │\n",
      "│ Akira ┆ 89    ┆ Dhaka  ┆ 21  │\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Saria ┆ 76    ┆ Ctg    ┆ 27  │\n",
      "└───────┴───────┴────────┴─────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mlf LazyFrame\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (4, 4)\n",
      "┌───────┬───────┬────────┬─────┐\n",
      "│ name  ┆ marks ┆ city   ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---    ┆ --- │\n",
      "│ str   ┆ i64   ┆ str    ┆ i64 │\n",
      "╞═══════╪═══════╪════════╪═════╡\n",
      "│ Saria ┆ 76    ┆ Ctg    ┆ 27  │\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Maria ┆ 79    ┆ Khulna ┆ 25  │\n",
      "│ Akira ┆ 89    ┆ Dhaka  ┆ 21  │\n",
      "└───────┴───────┴────────┴─────┘  \u001b[1;92m-->\u001b[0m unique(keep='last')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 4)\n",
      "┌───────┬───────┬───────┬─────┐\n",
      "│ name  ┆ marks ┆ city  ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---   ┆ --- │\n",
      "│ str   ┆ i64   ┆ str   ┆ i64 │\n",
      "╞═══════╪═══════╪═══════╪═════╡\n",
      "│ Saria ┆ 76    ┆ Ctg   ┆ 27  │\n",
      "│ Maria ┆ 79    ┆ Dhaka ┆ 23  │\n",
      "│ Akira ┆ 89    ┆ Dhaka ┆ 21  │\n",
      "└───────┴───────┴───────┴─────┘  \u001b[1;92m-->\u001b[0m unique(subset=['name', 'marks'], keep='last')\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (1, 4)\n",
      "┌──────┬───────┬──────┬─────┐\n",
      "│ name ┆ marks ┆ city ┆ age │\n",
      "│ ---  ┆ ---   ┆ ---  ┆ --- │\n",
      "│ u32  ┆ u32   ┆ u32  ┆ u32 │\n",
      "╞══════╪═══════╪══════╪═════╡\n",
      "│ 3    ┆ 3     ┆ 3    ┆ 4   │\n",
      "└──────┴───────┴──────┴─────┘  \u001b[1;92m-->\u001b[0m Unique Number of Values on Each Column\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lf = pl.scan_csv(\"D:\\\\datasets\\\\drop_duplicate.csv\")\n",
    "print(lf.collect(), extra_info(color_text(\"lf LazyFrame\")))\n",
    "\n",
    "print(lf.unique(keep='last').collect(), extra_info(\"unique(keep='last')\"))\n",
    "print(lf.unique(subset=['name', 'marks'], keep='last').collect(), extra_info(\"unique(subset=['name', 'marks'], keep='last')\"))\n",
    "\n",
    "# LazyFrame.approx_n_unique() ESTIMATES -UNIQUE VALUES \"ON EACH COLUMN\"- , -not 'unique rows count'-.\n",
    "# print(lf.approx_n_unique().collect(), extra_info(\"lf.approx_n_unique()\")) # `LazyFrame.approx_n_unique` is deprecated.\n",
    "print(lf.select(pl.all().approx_n_unique()).collect(),  extra_info(\"Unique Number of Values on Each Column\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                           drop(`*Column Names`, strict), drop rows\n",
    "```js\n",
    "        1. '*Column Names' = 'age', 'name'\n",
    "                       or  = ['age', 'name'], ultimately it will be unpacked(*).\n",
    "        2. strict = throw an exception if a column name does not exist(True) OR not(False).\n",
    "        3. If you want to drop 'rows', use filter() as filter()'s job is to filter/drop rows based on a or multiple conditions.\n",
    "\n",
    "           i) But dropping a row by 'index'? In that case we need to have a 'index column'.'lazyframe.with_row_index(Name, startIndex)' add a row index as the first column in the LazyFrame.\n",
    "           ii) Or you can slice(index, length). [:] --> This slice wont work because [:] works with DataFrame or Series because in LazyFrame the table data has not made till we call collect() and without table data we can't use [:]'. For 'LazyFrame its slice(index, length)'. After using slice(..) concatenate() them by 'vertically', cant use 'vstack' for Lazayframes.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────┬───────┬────────┬─────┐\n",
      "│ name  ┆ marks ┆ city   ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---    ┆ --- │\n",
      "│ str   ┆ i64   ┆ str    ┆ i64 │\n",
      "╞═══════╪═══════╪════════╪═════╡\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Maria ┆ 79    ┆ Khulna ┆ 25  │\n",
      "│ Akira ┆ 89    ┆ Dhaka  ┆ 21  │\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Saria ┆ 76    ┆ Ctg    ┆ 27  │\n",
      "└───────┴───────┴────────┴─────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mlf LazyFrame\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (5, 2)\n",
      "┌───────┬────────┐\n",
      "│ marks ┆ city   │\n",
      "│ ---   ┆ ---    │\n",
      "│ i64   ┆ str    │\n",
      "╞═══════╪════════╡\n",
      "│ 79    ┆ Dhaka  │\n",
      "│ 79    ┆ Khulna │\n",
      "│ 89    ┆ Dhaka  │\n",
      "│ 79    ┆ Dhaka  │\n",
      "│ 76    ┆ Ctg    │\n",
      "└───────┴────────┘  \u001b[1;92m-->\u001b[0m drop('age', 'name') columns.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 4)\n",
      "┌───────┬───────┬───────┬─────┐\n",
      "│ name  ┆ marks ┆ city  ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---   ┆ --- │\n",
      "│ str   ┆ i64   ┆ str   ┆ i64 │\n",
      "╞═══════╪═══════╪═══════╪═════╡\n",
      "│ Maria ┆ 79    ┆ Dhaka ┆ 23  │\n",
      "│ Akira ┆ 89    ┆ Dhaka ┆ 21  │\n",
      "│ Saria ┆ 76    ┆ Ctg   ┆ 27  │\n",
      "└───────┴───────┴───────┴─────┘  \u001b[1;92m-->\u001b[0m Dropped the index 1 and 3\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (5, 5)\n",
      "┌───────┬───────┬───────┬────────┬─────┐\n",
      "│ index ┆ name  ┆ marks ┆ city   ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---   ┆ ---    ┆ --- │\n",
      "│ u32   ┆ str   ┆ i64   ┆ str    ┆ i64 │\n",
      "╞═══════╪═══════╪═══════╪════════╪═════╡\n",
      "│ 0     ┆ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ 1     ┆ Maria ┆ 79    ┆ Khulna ┆ 25  │\n",
      "│ 2     ┆ Akira ┆ 89    ┆ Dhaka  ┆ 21  │\n",
      "│ 3     ┆ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ 4     ┆ Saria ┆ 76    ┆ Ctg    ┆ 27  │\n",
      "└───────┴───────┴───────┴────────┴─────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mlf1 LazyFrame having Index Column at very First\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 5)\n",
      "┌───────┬───────┬───────┬───────┬─────┐\n",
      "│ index ┆ name  ┆ marks ┆ city  ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---   ┆ ---   ┆ --- │\n",
      "│ u32   ┆ str   ┆ i64   ┆ str   ┆ i64 │\n",
      "╞═══════╪═══════╪═══════╪═══════╪═════╡\n",
      "│ 0     ┆ Maria ┆ 79    ┆ Dhaka ┆ 23  │\n",
      "│ 2     ┆ Akira ┆ 89    ┆ Dhaka ┆ 21  │\n",
      "│ 4     ┆ Saria ┆ 76    ┆ Ctg   ┆ 27  │\n",
      "└───────┴───────┴───────┴───────┴─────┘  \u001b[1;92m-->\u001b[0m Dropped the index 1 and 3\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lf.collect(), extra_info(color_text(\"lf LazyFrame\")))\n",
    "print(lf.drop('age', 'name').collect(), extra_info(\"drop('age', 'name') columns.\"))\n",
    "\n",
    "# Drop the Index 1 and 3. slice(4, length = None) means slice from index 4 to the last column.\n",
    "# solution 1\n",
    "lf_temp = pl.concat([lf.slice(0, 1), lf.slice(2, 1), lf.slice(4, length=None)], how='vertical_relaxed')\n",
    "print(lf_temp.collect(), extra_info(\"Dropped the index 1 and 3\"))\n",
    "\n",
    "# solution 2\n",
    "lf1 = lf.with_row_index(name='index')\n",
    "print(lf1.collect(), extra_info(color_text(\"lf1 LazyFrame having Index Column at very First\")))\n",
    "print( lf1.filter(~pl.col('index').is_in([1, 3])).collect(), extra_info(\"Dropped the index 1 and 3\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                   sort(by, descending, nulls_last, ...) LazyFrame\n",
    "```js\n",
    "        by = based on what columns, e.g. ['age', 'marks']\n",
    "        descending = for each column in 'by' do you want that column in descending or not, e.g. `[False, True]`.\n",
    "        nulls_last = After sorting where the nulls value should be? At the 'last' or not, e.g. 'True' or 'False'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────┬───────┬────────┬─────┐\n",
      "│ name  ┆ marks ┆ city   ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---    ┆ --- │\n",
      "│ str   ┆ i64   ┆ str    ┆ i64 │\n",
      "╞═══════╪═══════╪════════╪═════╡\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Maria ┆ 79    ┆ Khulna ┆ 25  │\n",
      "│ Akira ┆ 89    ┆ Dhaka  ┆ 21  │\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Saria ┆ 76    ┆ Ctg    ┆ 27  │\n",
      "└───────┴───────┴────────┴─────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mlf LazyFrame\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>marks</th><th>city</th><th>age</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Akira&quot;</td><td>89</td><td>&quot;Dhaka&quot;</td><td>21</td></tr><tr><td>&quot;Maria&quot;</td><td>79</td><td>&quot;Dhaka&quot;</td><td>23</td></tr><tr><td>&quot;Maria&quot;</td><td>79</td><td>&quot;Dhaka&quot;</td><td>23</td></tr><tr><td>&quot;Maria&quot;</td><td>79</td><td>&quot;Khulna&quot;</td><td>25</td></tr><tr><td>&quot;Saria&quot;</td><td>76</td><td>&quot;Ctg&quot;</td><td>27</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────┬───────┬────────┬─────┐\n",
       "│ name  ┆ marks ┆ city   ┆ age │\n",
       "│ ---   ┆ ---   ┆ ---    ┆ --- │\n",
       "│ str   ┆ i64   ┆ str    ┆ i64 │\n",
       "╞═══════╪═══════╪════════╪═════╡\n",
       "│ Akira ┆ 89    ┆ Dhaka  ┆ 21  │\n",
       "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
       "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
       "│ Maria ┆ 79    ┆ Khulna ┆ 25  │\n",
       "│ Saria ┆ 76    ┆ Ctg    ┆ 27  │\n",
       "└───────┴───────┴────────┴─────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lf.collect(), extra_info(color_text(\"lf LazyFrame\")))\n",
    "lf.sort(by=['age', 'marks'], descending=[False, True], nulls_last=True).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                           pl.when(`condition`).then(`do this`).otherwise(`do that`)\n",
    "```js\n",
    "        'condition' = An Expression.\n",
    "        'do this'   = An Expression or A Scaler Value.\n",
    "        'do that'   = An Expression or A Scaler Value.\n",
    "    \n",
    "        Dont skip -- otherwise(`do that`) -- part even if you just want to do -- pl.when(`condition`).then(`do this`) -- operation. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────┬───────┬────────┬─────┐\n",
      "│ name  ┆ marks ┆ city   ┆ age │\n",
      "│ ---   ┆ ---   ┆ ---    ┆ --- │\n",
      "│ str   ┆ i64   ┆ str    ┆ i64 │\n",
      "╞═══════╪═══════╪════════╪═════╡\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Maria ┆ 79    ┆ Khulna ┆ 25  │\n",
      "│ Akira ┆ 89    ┆ Dhaka  ┆ 21  │\n",
      "│ Maria ┆ 79    ┆ Dhaka  ┆ 23  │\n",
      "│ Saria ┆ 76    ┆ Ctg    ┆ 27  │\n",
      "└───────┴───────┴────────┴─────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mlf LazyFrame\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>marks</th><th>city</th><th>age</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Maria&quot;</td><td>80</td><td>&quot;Dhaka&quot;</td><td>23</td></tr><tr><td>&quot;Maria&quot;</td><td>80</td><td>&quot;Khulna&quot;</td><td>25</td></tr><tr><td>&quot;Akira&quot;</td><td>90</td><td>&quot;Dhaka&quot;</td><td>21</td></tr><tr><td>&quot;Maria&quot;</td><td>80</td><td>&quot;Dhaka&quot;</td><td>23</td></tr><tr><td>&quot;Saria&quot;</td><td>76</td><td>&quot;Ctg&quot;</td><td>27</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────┬───────┬────────┬─────┐\n",
       "│ name  ┆ marks ┆ city   ┆ age │\n",
       "│ ---   ┆ ---   ┆ ---    ┆ --- │\n",
       "│ str   ┆ i64   ┆ str    ┆ i64 │\n",
       "╞═══════╪═══════╪════════╪═════╡\n",
       "│ Maria ┆ 80    ┆ Dhaka  ┆ 23  │\n",
       "│ Maria ┆ 80    ┆ Khulna ┆ 25  │\n",
       "│ Akira ┆ 90    ┆ Dhaka  ┆ 21  │\n",
       "│ Maria ┆ 80    ┆ Dhaka  ┆ 23  │\n",
       "│ Saria ┆ 76    ┆ Ctg    ┆ 27  │\n",
       "└───────┴───────┴────────┴─────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lf.collect(), extra_info(color_text(\"lf LazyFrame\")))\n",
    "\n",
    "condition: pl.Expr = (pl.col('marks') % 10).is_between(7, 9)\n",
    "round_it: pl.Expr = ((pl.col('marks') // 10) + 1) * 10 # e.g. turn 57|58|59 to 60.\n",
    "keep_it_as_it_is = pl.col('marks')\n",
    "\n",
    "lf.with_columns(pl.when(condition).then(round_it).otherwise(keep_it_as_it_is)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                               group_by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "        Look at 'group_by object.png' which is in this 'polars' folder. After doing 'group_by(by=..)', it returns a 'LazyGroupBy' object. Assume 'group1' is the group_by object in that image. Each 'key' in 'group1' has its own 'value(LazyFrame)'.\n",
    "        Now 'group1.count()' means this 'count()' will be applied on 'each value(LazyFrame)'. So doesnt matter what function you apply on '(group1)' except `map_groups()`, because that (function) will be applied on (each value(LazyFrame)).\n",
    "\n",
    "        Usage:\n",
    "        ------\n",
    "        Why we create group_by object? To perform ANY OPERATION on each group inside that group_by object.\n",
    "        1) Now when we perform sum(), mean(), first(), last() etc on a LazyFrame, we get 'A Single Value' for each column in that LazyFrame.\n",
    "        2) But when we perform cum_sum(), is_null() etc on A LazyFrame, we get 'A Column' for each Column in that LazyFrame.\n",
    "                However if you apply them on a 'LazyGroupBy' object, For Each Group(LazyFrame): You get 'A List of Values, list(A Column)' for each column, so the answer can lies on a 'Single Row' e.g. [1, 2, 3, 4].\n",
    "           \n",
    "           After typing 'group10.' you will see only some functions BUT with group10.agg( col(..).choose_any_function() ). And of course we cant do 'select(), with_columns(), filter()' in agg(), but you can sure select specific columns inside agg() like we do with select().\n",
    "\n",
    "           REMEMBER : 'is_null()', 'cum_sum()' etc inside 'agg()' return 'A LIST OF VALUES'(i.e. 'A SINGLE VALUE') for each COLUMN and this is called 'AGGREGATION' since we are using 'agg()'.\n",
    "\n",
    "           WARNING : ALWAYS USE .agg() in group_by object to select built-in functions to do AGGREGATION('A SINGLE VALUE(SCALER/LIST egal) FOR EACH COLUMN in EACH GROUP'), why?? 'group1.count()' is not explicitly saying if the count() being applied row or column wise BUT \"group1.agg( col('*').count() )\" explicitly saying that it is being applied column-wise. But for custom function use map_groups().\n",
    "                     Be carefull when using agg(..) since agg() AGGREGATES the result into a SINGLE VALUE i.e. {A SINGLE VALUE(Scaler/List) for EACH COLUMN}. So if you want A COLUMN for EACH COLUMN, you need to use 'CUSTOM FUNCTION' i.e. map_groups().\n",
    "        \n",
    "        Output:\n",
    "        -------\n",
    "        Now after you apply functions on 'group1' you will get a 'LazyFrame' result where the 'First Column = 'keys' of groupby object 'group1' and it is in random order.\n",
    "        \n",
    "        Note:\n",
    "        -----\n",
    "        LazyFrame.map_groups(lambda column: ....) => LazyFrame is nothing but 'bunch of columns'. When we map_groups() on LazyFrame, 'first we grab a column' and 'then traverse through each value of that column manually OR can apply vectorize operation (column.is_null()..) on that column'. Similarly for rest columns.\n",
    "\n",
    "        LazyFrameGroupByObject.map_groups(lambda group: .... ) => group_by object consists of many 'group(Talking about each LazyFrame, not the keys)'. When we map_groups() on a group_by_object, 'first we grab teh first group(LazyFrame)', 'then we can apply vectorize operation on the whole group(Lazyframe) like Lazyframe.count()' OR 'we can traverse each column MANUALLY like we do on LazyFrame.map_groups(lambda column: ....)'. Similarly for rest groups.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                        map_groups() on group_by object.\n",
    "```js\n",
    "        How map_groups() works :\n",
    "\n",
    "            1) 'splits' each group(LazyFrame) into a Accessible LazyFrame. Thats why in map_groups(lambda LazyFrame:...), we can use the LazyFrame keyword as a Real LazyFrame.\n",
    "            2) Then do the 'operation(function)' we set into map_groups(..) and get 'output(Scaler value/LazyFrame(A Single Column)/LazyFrame(Multiple Columns))' for EACH group(LazyFrame).\n",
    "            3) 'Merge' EACH 'output' and return them as A LazyFrame.\n",
    "      \n",
    "         Note: At Step 2, we 'must return the output' we want for each group(LazyFrame). Otherwise what will we MERGE at the end? YOUR \n",
    "               MUM? NO!\n",
    "               Dont think about the other groups(LazyFrames), 'focus on the first group' that 'WHAT you want to RETURN' after doing the calculation on that group(LazyFrame). If its a Single Boolean Column, other groups will also return a Single Boolean Column from each, eventually all SEPERATED OUTPUT will be merged into a SINGLE OUTPUT. So if we understand what the first LazyFrame will return, we can guess what the final merged output will be. Thats why focus on the first group(LazyFrame).\n",
    "\n",
    "                  For e.g. we want to return a LazyFrame adding a new column. (speaking for the first group(LazyFrame))\n",
    "\n",
    "                  def add_new_column(lazyframe) -> pl.LazyFrame:\n",
    "                     new_lazyframe_after_adding_a_column = lazyframe.with_columns(col('a').rank(descending=True).alias('ranking on a'))\n",
    "                     return new_lazyframe_after_adding_a_column\n",
    "\n",
    "                  result = groupby_object.map_groups(func= add_new_column, schema=None)\n",
    "                                          --> map_groups(..) will also be applied on rest groups(LazyFrames), ultimately will return a big big LazyFrame MERGING THOSE NEW LazyFrames.\n",
    "                  \n",
    "               So again : 'focus on the first group' that 'WHAT you want to return from this group(LazyFrame)'.\n",
    "                          Ohh! All the LazyFrame, Column we can access inside map_groups(..), they are all copy! Mess with them, change them, no issue.\n",
    "\n",
    "               Even during 'agg(..)' 'focus on the first group' that 'WHAT you want to return from this group(LazyFrame)'..\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<polars.lazyframe.group_by.LazyGroupBy object at 0x0000023FA90C3AD0>  \u001b[1;92m-->\u001b[0m group_by object 'group10'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (8, 4)\n",
      "┌─────┬─────┬─────┬────────┐\n",
      "│ b   ┆ a   ┆ c   ┆ d      │\n",
      "│ --- ┆ --- ┆ --- ┆ ---    │\n",
      "│ str ┆ i64 ┆ i64 ┆ str    │\n",
      "╞═════╪═════╪═════╪════════╡\n",
      "│ 1   ┆ 8   ┆ 9   ┆ Akira  │\n",
      "│     ┆ 6   ┆ 5   ┆ Hova   │\n",
      "│     ┆ 4   ┆ 7   ┆ Saria  │\n",
      "│ 2   ┆ 5   ┆ 8   ┆ Mukail │\n",
      "│     ┆ 7   ┆ 0   ┆ Maria  │\n",
      "│     ┆ 7   ┆ 3   ┆ Masha  │\n",
      "│ 3   ┆ 1   ┆ 8   ┆ Alya   │\n",
      "│     ┆ 2   ┆ 8   ┆ Aliya  │\n",
      "└─────┴─────┴─────┴────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mgroup10\u001b[0m_appearance\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 4)\n",
      "┌─────┬───────────┬───────────┬──────────────────────────────┐\n",
      "│ b   ┆ a         ┆ c         ┆ d                            │\n",
      "│ --- ┆ ---       ┆ ---       ┆ ---                          │\n",
      "│ i64 ┆ list[i64] ┆ list[i64] ┆ list[str]                    │\n",
      "╞═════╪═══════════╪═══════════╪══════════════════════════════╡\n",
      "│ 2   ┆ [5, 7, 7] ┆ [8, 0, 3] ┆ [\"Mukail\", \"Maria\", \"Masha\"] │\n",
      "│ 1   ┆ [8, 6, 4] ┆ [9, 5, 7] ┆ [\"Akira\", \"Hova\", \"Saria\"]   │\n",
      "│ 3   ┆ [1, 2]    ┆ [8, 8]    ┆ [\"Alya\", \"Aliya\"]            │\n",
      "└─────┴───────────┴───────────┴──────────────────────────────┘  \u001b[1;92m-->\u001b[0m group10.agg(col('a'), col('c'), col('d'))\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[shape: (3, 4)\n",
      "┌─────┬─────┬─────┬────────┐\n",
      "│ a   ┆ b   ┆ c   ┆ d      │\n",
      "│ --- ┆ --- ┆ --- ┆ ---    │\n",
      "│ i64 ┆ i64 ┆ i64 ┆ str    │\n",
      "╞═════╪═════╪═════╪════════╡\n",
      "│ 5   ┆ 2   ┆ 8   ┆ Mukail │\n",
      "│ 7   ┆ 2   ┆ 0   ┆ Maria  │\n",
      "│ 7   ┆ 2   ┆ 3   ┆ Masha  │\n",
      "└─────┴─────┴─────┴────────┘, shape: (3, 4)\n",
      "┌─────┬─────┬─────┬───────┐\n",
      "│ a   ┆ b   ┆ c   ┆ d     │\n",
      "│ --- ┆ --- ┆ --- ┆ ---   │\n",
      "│ i64 ┆ i64 ┆ i64 ┆ str   │\n",
      "╞═════╪═════╪═════╪═══════╡\n",
      "│ 8   ┆ 1   ┆ 9   ┆ Akira │\n",
      "│ 6   ┆ 1   ┆ 5   ┆ Hova  │\n",
      "│ 4   ┆ 1   ┆ 7   ┆ Saria │\n",
      "└─────┴─────┴─────┴───────┘, shape: (2, 4)\n",
      "┌─────┬─────┬─────┬───────┐\n",
      "│ a   ┆ b   ┆ c   ┆ d     │\n",
      "│ --- ┆ --- ┆ --- ┆ ---   │\n",
      "│ i64 ┆ i64 ┆ i64 ┆ str   │\n",
      "╞═════╪═════╪═════╪═══════╡\n",
      "│ 1   ┆ 3   ┆ 8   ┆ Alya  │\n",
      "│ 2   ┆ 3   ┆ 8   ┆ Aliya │\n",
      "└─────┴─────┴─────┴───────┘]  \u001b[1;92m-->\u001b[0m lf2.collect().partition_by(by='b') = Divide the DataFrame by col('b') into 'list of dataframes'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['Maria', 'Saria', 'Akira', 'Masha', 'Aliya', 'Alya', 'Mukail', 'Hova']\n",
    "data = {                          \n",
    "    'a': [5, 8, 7, 1, 6, 2, 7, 4],\n",
    "    'b': [2, 1, 2, 3, 1, 3, 2, 1],\n",
    "    'c': [8, 9, 0, 8, 5, 8, 3, 7],\n",
    "    'd': np.random.choice(a=names, size=(8,), replace=False)}\n",
    "\n",
    "lf2 = pl.LazyFrame(data)\n",
    "group10 = lf2.group_by('b')\n",
    "print(group10, extra_info(\"group_by object 'group10'\"))\n",
    "\n",
    "group10_appearance = lf2.sort(by='b').with_columns(b = pl.when( ~col('b').is_first_distinct() ).then(pl.lit('')).otherwise(col('b'))) .select(col('b', 'a'), col('*').exclude('b', 'a'))\n",
    "\n",
    "print(group10_appearance.collect(), extra_info(f\"{color_text(\"group10\")}_appearance\"))\n",
    "print(group10.agg(col('a'), col('c'), col('d')).collect(), extra_info(\"group10.agg(col('a'), col('c'), col('d'))\"))\n",
    "# Above : col('a') inside agg(..) working as an AGGREGATION, means all the values inside column 'a' will be returned as a SINGLE VALUE(here, as a List). Same for col('c') and col('d').\n",
    "\n",
    "print(lf2.collect().partition_by(by='b'), extra_info(\"lf2.collect().partition_by(by='b') = Divide the DataFrame by col('b') into 'list of dataframes'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;92m                Whatever you do, the FIRST COLUMN will by the group_by object's key which is col('b')\u001b[0m \n",
      "\n",
      "shape: (3, 1)\n",
      "┌─────┐\n",
      "│ b   │\n",
      "│ --- │\n",
      "│ i64 │\n",
      "╞═════╡\n",
      "│ 1   │\n",
      "│ 2   │\n",
      "│ 3   │\n",
      "└─────┘  \u001b[1;92m-->\u001b[0m lf2.select(col('b').unique()) = unique keys of 'group10'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 4)\n",
      "┌─────┬─────┬─────┬──────┐\n",
      "│ b   ┆ a   ┆ c   ┆ d    │\n",
      "│ --- ┆ --- ┆ --- ┆ ---  │\n",
      "│ i64 ┆ i64 ┆ i64 ┆ str  │\n",
      "╞═════╪═════╪═════╪══════╡\n",
      "│ 2   ┆ 19  ┆ 11  ┆ null │\n",
      "│ 3   ┆ 3   ┆ 16  ┆ null │\n",
      "│ 1   ┆ 18  ┆ 21  ┆ null │\n",
      "└─────┴─────┴─────┴──────┘  \u001b[1;92m-->\u001b[0m group10.sum()\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 4)\n",
      "┌─────┬─────┬─────┬──────┐\n",
      "│ b   ┆ a   ┆ c   ┆ d    │\n",
      "│ --- ┆ --- ┆ --- ┆ ---  │\n",
      "│ i64 ┆ i64 ┆ i64 ┆ str  │\n",
      "╞═════╪═════╪═════╪══════╡\n",
      "│ 3   ┆ 3   ┆ 16  ┆ null │\n",
      "│ 1   ┆ 18  ┆ 21  ┆ null │\n",
      "│ 2   ┆ 19  ┆ 11  ┆ null │\n",
      "└─────┴─────┴─────┴──────┘  \u001b[1;92m-->\u001b[0m group10.agg(col('*').sum()\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (8, 4)\n",
      "┌─────┬─────┬─────┬────────┐\n",
      "│ b   ┆ a   ┆ c   ┆ d      │\n",
      "│ --- ┆ --- ┆ --- ┆ ---    │\n",
      "│ str ┆ i64 ┆ i64 ┆ str    │\n",
      "╞═════╪═════╪═════╪════════╡\n",
      "│ 1   ┆ 8   ┆ 9   ┆ Akira  │\n",
      "│     ┆ 6   ┆ 5   ┆ Hova   │\n",
      "│     ┆ 4   ┆ 7   ┆ Saria  │\n",
      "│ 2   ┆ 5   ┆ 8   ┆ Mukail │\n",
      "│     ┆ 7   ┆ 0   ┆ Maria  │\n",
      "│     ┆ 7   ┆ 3   ┆ Masha  │\n",
      "│ 3   ┆ 1   ┆ 8   ┆ Alya   │\n",
      "│     ┆ 2   ┆ 8   ┆ Aliya  │\n",
      "└─────┴─────┴─────┴────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mgroup10\u001b[0m_appearance\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌─────┬─────────────┬─────────────┐\n",
      "│ b   ┆ a           ┆ c           │\n",
      "│ --- ┆ ---         ┆ ---         │\n",
      "│ i64 ┆ list[i64]   ┆ list[i64]   │\n",
      "╞═════╪═════════════╪═════════════╡\n",
      "│ 1   ┆ [8, 14, 18] ┆ [9, 14, 21] │\n",
      "│ 2   ┆ [5, 12, 19] ┆ [8, 8, 11]  │\n",
      "│ 3   ┆ [1, 3]      ┆ [8, 16]     │\n",
      "└─────┴─────────────┴─────────────┘  \u001b[1;92m-->\u001b[0m group10.agg(col('a', 'c').cum_sum()\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌─────┬───────────────────────┬───────────────────────┐\n",
      "│ b   ┆ a                     ┆ c                     │\n",
      "│ --- ┆ ---                   ┆ ---                   │\n",
      "│ i64 ┆ list[bool]            ┆ list[bool]            │\n",
      "╞═════╪═══════════════════════╪═══════════════════════╡\n",
      "│ 1   ┆ [false, false, false] ┆ [false, false, false] │\n",
      "│ 3   ┆ [false, false]        ┆ [false, false]        │\n",
      "│ 2   ┆ [false, false, false] ┆ [false, false, false] │\n",
      "└─────┴───────────────────────┴───────────────────────┘  \u001b[1;92m-->\u001b[0m group10.agg(col('a', 'c').is_null()\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (8, 4)\n",
      "┌─────┬─────┬─────┬────────┐\n",
      "│ b   ┆ a   ┆ c   ┆ d      │\n",
      "│ --- ┆ --- ┆ --- ┆ ---    │\n",
      "│ str ┆ i64 ┆ i64 ┆ str    │\n",
      "╞═════╪═════╪═════╪════════╡\n",
      "│ 1   ┆ 8   ┆ 9   ┆ Akira  │\n",
      "│     ┆ 6   ┆ 5   ┆ Hova   │\n",
      "│     ┆ 4   ┆ 7   ┆ Saria  │\n",
      "│ 2   ┆ 5   ┆ 8   ┆ Mukail │\n",
      "│     ┆ 7   ┆ 0   ┆ Maria  │\n",
      "│     ┆ 7   ┆ 3   ┆ Masha  │\n",
      "│ 3   ┆ 1   ┆ 8   ┆ Alya   │\n",
      "│     ┆ 2   ┆ 8   ┆ Aliya  │\n",
      "└─────┴─────┴─────┴────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mgroup10\u001b[0m_appearance\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 2)\n",
      "┌─────┬─────┐\n",
      "│ b   ┆ len │\n",
      "│ --- ┆ --- │\n",
      "│ i64 ┆ u32 │\n",
      "╞═════╪═════╡\n",
      "│ 3   ┆ 2   │\n",
      "│ 2   ┆ 3   │\n",
      "│ 1   ┆ 3   │\n",
      "└─────┴─────┘  \u001b[1;92m-->\u001b[0m group10.len() = (key = The frequency of that key in col('b'))\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 3)\n",
      "┌─────┬─────┬────────┐\n",
      "│ b   ┆ a   ┆ d      │\n",
      "│ --- ┆ --- ┆ ---    │\n",
      "│ i64 ┆ i64 ┆ str    │\n",
      "╞═════╪═════╪════════╡\n",
      "│ 2   ┆ 5   ┆ Mukail │\n",
      "│ 3   ┆ 1   ┆ Alya   │\n",
      "│ 1   ┆ 8   ┆ Akira  │\n",
      "└─────┴─────┴────────┘  \u001b[1;92m-->\u001b[0m group10.agg(col('a', 'd').first())\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(color_text(\"                Whatever you do, the FIRST COLUMN will by the group_by object's key which is col('b')\"), '\\n')\n",
    "\n",
    "# We can't access the keys of this group_by object 'group10'. Alternative is unique().\n",
    "print( lf2.select(col('b').unique()).collect() , extra_info(\"lf2.select(col('b').unique()) = unique keys of 'group10'\"))\n",
    "\n",
    "print(group10.sum().collect(), extra_info(\"group10.sum()\"))\n",
    "print(group10.agg(col('*').sum()).collect(), extra_info(\"group10.agg(col('*').sum()\"))\n",
    "\n",
    "print(group10_appearance.collect(), extra_info(f\"{color_text(\"group10\")}_appearance\"))\n",
    "print(group10.agg(col('a', 'c').cum_sum()).collect(), extra_info(\"group10.agg(col('a', 'c').cum_sum()\"))\n",
    "print(group10.agg(col('a', 'c').is_null()).collect(), extra_info(\"group10.agg(col('a', 'c').is_null()\"))\n",
    "\n",
    "print(group10_appearance.collect(), extra_info(f\"{color_text(\"group10\")}_appearance\"))\n",
    "print(group10.len().collect(), extra_info(\"group10.len() = (key = The frequency of that key in col('b'))\"))\n",
    "\n",
    "print(group10.agg(col('a', 'd').first()).collect(), extra_info(\"group10.agg(col('a', 'd').first())\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8, 4)\n",
      "┌─────┬─────┬─────┬────────┐\n",
      "│ b   ┆ a   ┆ c   ┆ d      │\n",
      "│ --- ┆ --- ┆ --- ┆ ---    │\n",
      "│ str ┆ i64 ┆ i64 ┆ str    │\n",
      "╞═════╪═════╪═════╪════════╡\n",
      "│ 1   ┆ 8   ┆ 9   ┆ Akira  │\n",
      "│     ┆ 6   ┆ 5   ┆ Hova   │\n",
      "│     ┆ 4   ┆ 7   ┆ Saria  │\n",
      "│ 2   ┆ 5   ┆ 8   ┆ Mukail │\n",
      "│     ┆ 7   ┆ 0   ┆ Maria  │\n",
      "│     ┆ 7   ┆ 3   ┆ Masha  │\n",
      "│ 3   ┆ 1   ┆ 8   ┆ Alya   │\n",
      "│     ┆ 2   ┆ 8   ┆ Aliya  │\n",
      "└─────┴─────┴─────┴────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mgroup10\u001b[0m_appearance\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 2)\n",
      "┌─────┬───────────────────────┐\n",
      "│ b   ┆ d                     │\n",
      "│ --- ┆ ---                   │\n",
      "│ i64 ┆ list[bool]            │\n",
      "╞═════╪═══════════════════════╡\n",
      "│ 1   ┆ [false, false, false] │\n",
      "│ 3   ┆ [false, false]        │\n",
      "│ 2   ┆ [true, true, true]    │\n",
      "└─────┴───────────────────────┘\n",
      " \u001b[1;92m-->\u001b[0m group10.agg( col('d').str.starts_with('M') ) => starts_with() returns True/False. Since its used as AGGREGATE FUNCTION, we get list of True/False.\n",
      "\u001b[1;92mSo be carefull when using agg(..) since agg() AGGREGATES the result.\u001b[0m\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (3, 2)\n",
      "┌─────┬────────┐\n",
      "│ b   ┆ d      │\n",
      "│ --- ┆ ---    │\n",
      "│ i64 ┆ str    │\n",
      "╞═════╪════════╡\n",
      "│ 2   ┆ Mukail │\n",
      "│ 2   ┆ Maria  │\n",
      "│ 2   ┆ Masha  │\n",
      "└─────┴────────┘  \u001b[1;92m-->\u001b[0m group10.map_groups(function=names_starts_with_M, schema=None)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q : Find all the names starts with 'M' in group10 object. (In other words: Filter the column 'd' with given condition for each group)\n",
    "\n",
    "print(group10_appearance.collect(), extra_info(f\"{color_text(\"group10\")}_appearance\"))\n",
    "\n",
    "print(group10.agg( col('d').str.starts_with('M') ).collect()) # agg() useless here to find the names explictely. Reason below:\n",
    "print(extra_info(f\"group10.agg( col('d').str.starts_with('M') ) => starts_with() returns True/False. Since its used as AGGREGATE FUNCTION, we get list of True/False.\\n{color_text(\"So be carefull when using agg(..) since agg() AGGREGATES the result.\")}\"))\n",
    "\n",
    "# Ans = For Each Group(LazyFrame) FILTER the column 'd' which we can't do with agg() but filter(). For these we need custom fuction.\n",
    "# Below Line : select('b', 'd') because if I do select('d'), only column 'd' will be in the output.\n",
    "names_starts_with_M: Callable[[pl.LazyFrame], pl.LazyFrame] = lambda lazyframe: lazyframe.select('b', 'd').filter(col('d').str.starts_with('M'))\n",
    "print(group10.map_groups(function=names_starts_with_M, schema=None).collect(), extra_info(\"group10.map_groups(function=names_starts_with_M, schema=None)\"))\n",
    "# Above : schema = Output Schema MANUALLY. schema=None means polars will decide what will be the OUTPUT DATATYPE for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8, 4)\n",
      "┌─────┬─────┬─────┬────────┐\n",
      "│ b   ┆ a   ┆ c   ┆ d      │\n",
      "│ --- ┆ --- ┆ --- ┆ ---    │\n",
      "│ str ┆ i64 ┆ i64 ┆ str    │\n",
      "╞═════╪═════╪═════╪════════╡\n",
      "│ 1   ┆ 8   ┆ 9   ┆ Akira  │\n",
      "│     ┆ 6   ┆ 5   ┆ Hova   │\n",
      "│     ┆ 4   ┆ 7   ┆ Saria  │\n",
      "│ 2   ┆ 5   ┆ 8   ┆ Mukail │\n",
      "│     ┆ 7   ┆ 0   ┆ Maria  │\n",
      "│     ┆ 7   ┆ 3   ┆ Masha  │\n",
      "│ 3   ┆ 1   ┆ 8   ┆ Alya   │\n",
      "│     ┆ 2   ┆ 8   ┆ Aliya  │\n",
      "└─────┴─────┴─────┴────────┘  \u001b[1;92m-->\u001b[0m \u001b[1;92mgroup10\u001b[0m_appearance\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "shape: (8, 5)\n",
      "┌─────┬─────┬─────┬────────┬──────────────┐\n",
      "│ a   ┆ b   ┆ c   ┆ d      ┆ ranking on a │\n",
      "│ --- ┆ --- ┆ --- ┆ ---    ┆ ---          │\n",
      "│ i64 ┆ i64 ┆ i64 ┆ str    ┆ f64          │\n",
      "╞═════╪═════╪═════╪════════╪══════════════╡\n",
      "│ 1   ┆ 3   ┆ 8   ┆ Alya   ┆ 2.0          │\n",
      "│ 2   ┆ 3   ┆ 8   ┆ Aliya  ┆ 1.0          │\n",
      "│ 5   ┆ 2   ┆ 8   ┆ Mukail ┆ 3.0          │\n",
      "│ 7   ┆ 2   ┆ 0   ┆ Maria  ┆ 1.5          │\n",
      "│ 7   ┆ 2   ┆ 3   ┆ Masha  ┆ 1.5          │\n",
      "│ 8   ┆ 1   ┆ 9   ┆ Akira  ┆ 1.0          │\n",
      "│ 6   ┆ 1   ┆ 5   ┆ Hova   ┆ 2.0          │\n",
      "│ 4   ┆ 1   ┆ 7   ┆ Saria  ┆ 3.0          │\n",
      "└─────┴─────┴─────┴────────┴──────────────┘\n",
      "\n",
      "The 'b' column is also shown in the output because (in my opinion) polars RANDOMLY select a group to do given calculation and\n",
      "RANDOMLY show them in the output WHICH IS FASTER AND EFFICIENT CALCULATION since no maintaining order is needed. So to help to\n",
      "recognize which values belongs to which group, polars show the column 'b' in the output.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q: For each group(in group1) find the Rank based on column 'a' and create a new column('ranking on a') to set the ranking output.\n",
    "\n",
    "print(group10_appearance.collect(), extra_info(f\"{color_text(\"group10\")}_appearance\"))\n",
    "\n",
    "def set_ranking_on_a(lazyframe: pl.LazyFrame) -> pl.LazyFrame: # this lazyframe is a COPY.\n",
    "    return lazyframe.with_columns(col('a').rank(descending=True).alias('ranking on a'))\n",
    "\n",
    "print(group10.map_groups(function=set_ranking_on_a, schema=None).collect())\n",
    "\n",
    "print('''\n",
    "The 'b' column is also shown in the output because (in my opinion) polars RANDOMLY select a group to do given calculation and\n",
    "RANDOMLY show them in the output WHICH IS FASTER AND EFFICIENT CALCULATION since no maintaining order is needed. So to help to\n",
    "recognize which values belongs to which group, polars show the column 'b' in the output.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "                                Speed comparison between pandas apply() and polars map_groups().\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['Maria', 'Saria', 'Akira', 'Masha', 'Aliya', 'Alya', 'Mukail', 'Hova']\n",
    "# a = list(range(10))\n",
    "# data = {                          \n",
    "#     'a': np.random.choice(a= a, size=(1_00_00000,), replace=True),\n",
    "#     'b': np.random.choice(a= a, size=(1_00_00000,), replace=True),\n",
    "#     'c': np.random.choice(a= a, size=(1_00_00000,), replace=True),\n",
    "#     'd': np.random.choice(a=names, size=(1_00_00000,), replace=True) }\n",
    "\n",
    "# df0 = pl.LazyFrame(data)\n",
    "# group0 = df0.group_by('b')\n",
    "\n",
    "# df1 = pl.DataFrame(data)\n",
    "# group1 = df1.group_by('b')\n",
    "\n",
    "# df2 = pd.DataFrame(data)\n",
    "# group2 = df2.groupby('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    0.7093157768249512  => LazyFrame\n",
      "    0.7516193389892578  => DataFrame (polars)\n",
      "    6.648420572280884   => DataFrame (pandas)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start = time()\n",
    "# find_names_M0: Callable[[pl.LazyFrame], pl.LazyFrame] = lambda lazyframe: lazyframe.filter(col('d').str.starts_with('M')).select(col('b', 'd'))\n",
    "# r0 = group0.map_groups(function= find_names_M0, schema=None).sort(by='b').collect()\n",
    "# print(time() - start)\n",
    "\n",
    "# start = time()\n",
    "# find_names_M1: Callable[[pl.DataFrame], pl.DataFrame] = lambda dataframe: dataframe.filter(col('d').str.starts_with('M')).select(col('b', 'd'))\n",
    "# r1 = group1.map_groups(function= find_names_M1).sort(by='b')\n",
    "# print(time() - start)\n",
    "\n",
    "# start = time()\n",
    "# find_names_M2: Callable[[pd.DataFrame], pd.DataFrame] = lambda dataframe: dataframe['d'] [dataframe['d'].str.startswith('M')]\n",
    "# r2 =  group2.apply(func= find_names_M2, include_groups=False)\n",
    "# print(time() - start)\n",
    "\n",
    "# Ans :\n",
    "print('''\n",
    "    0.7093157768249512  => LazyFrame\n",
    "    0.7516193389892578  => DataFrame (polars)\n",
    "    6.648420572280884   => DataFrame (pandas)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape: (3_751_334, 2)\n",
      "┌─────┬────────┐\n",
      "│ b   ┆ d      │\n",
      "│ --- ┆ ---    │\n",
      "│ i64 ┆ str    │\n",
      "╞═════╪════════╡\n",
      "│ 0   ┆ Maria  │\n",
      "│ 0   ┆ Mukail │\n",
      "│ 0   ┆ Mukail │\n",
      "│ 0   ┆ Masha  │\n",
      "│ 0   ┆ Masha  │\n",
      "│ …   ┆ …      │\n",
      "│ 9   ┆ Masha  │\n",
      "│ 9   ┆ Mukail │\n",
      "│ 9   ┆ Mukail │\n",
      "│ 9   ┆ Maria  │\n",
      "│ 9   ┆ Masha  │\n",
      "└─────┴────────┘  --> polars dataframe\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "b\n",
      "0     Maria\n",
      "0    Mukail\n",
      "0    Mukail\n",
      "0     Masha\n",
      "0     Masha\n",
      "      ...  \n",
      "9     Masha\n",
      "9    Mukail\n",
      "9    Mukail\n",
      "9     Maria\n",
      "9     Masha\n",
      "Name: d, Length: 3751334, dtype: object  --> pandas\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(r1, extra_info(\"polars dataframe\"))\n",
    "# print(r2.droplevel(1), extra_info(\"pandas\"))\n",
    "\n",
    "print('''\n",
    "shape: (3_751_334, 2)\n",
    "┌─────┬────────┐\n",
    "│ b   ┆ d      │\n",
    "│ --- ┆ ---    │\n",
    "│ i64 ┆ str    │\n",
    "╞═════╪════════╡\n",
    "│ 0   ┆ Maria  │\n",
    "│ 0   ┆ Mukail │\n",
    "│ 0   ┆ Mukail │\n",
    "│ 0   ┆ Masha  │\n",
    "│ 0   ┆ Masha  │\n",
    "│ …   ┆ …      │\n",
    "│ 9   ┆ Masha  │\n",
    "│ 9   ┆ Mukail │\n",
    "│ 9   ┆ Mukail │\n",
    "│ 9   ┆ Maria  │\n",
    "│ 9   ┆ Masha  │\n",
    "└─────┴────────┘  --> polars dataframe\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "b\n",
    "0     Maria\n",
    "0    Mukail\n",
    "0    Mukail\n",
    "0     Masha\n",
    "0     Masha\n",
    "      ...  \n",
    "9     Masha\n",
    "9    Mukail\n",
    "9    Mukail\n",
    "9     Maria\n",
    "9     Masha\n",
    "Name: d, Length: 3751334, dtype: object  --> pandas\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (15, 2)\n",
      "┌─────┬─────────────────────────────────┐\n",
      "│ No  ┆ Name                            │\n",
      "│ --- ┆ ---                             │\n",
      "│ i8  ┆ str                             │\n",
      "╞═════╪═════════════════════════════════╡\n",
      "│ 1   ┆ Evaluating Deep Neural Network… │\n",
      "│ 2   ┆ SkinCon: A skin disease datase… │\n",
      "│ 3   ┆ Towards Transparency in Dermat… │\n",
      "│ 4   ┆ SkinCAP: A Multi-modal Dermato… │\n",
      "│ 5   ┆ Assessing GPT-4's Diagnostic A… │\n",
      "│ …   ┆ …                               │\n",
      "│ 11  ┆ Pre-trained multimodal large l… │\n",
      "│ 12  ┆ Unsupervised SoftOtsuNet Augme… │\n",
      "│ 13  ┆ Fostering transparent medical … │\n",
      "│ 14  ┆ Fair Conformal Predictors for … │\n",
      "│ 15  ┆ null                            │\n",
      "└─────┴─────────────────────────────────┘  \u001b[1;92m-->\u001b[0m \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = pl.scan_csv(\"d:\\\\datasets\\\\20 Paper Names.csv\", schema={'No': pl.Int8, 'Name': pl.String})\n",
    "\n",
    "print(df3.collect(), extra_info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
